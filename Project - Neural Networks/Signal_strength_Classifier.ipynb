{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "toxic-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occupied-syntax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.089</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.114</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.176</td>\n",
       "      <td>52.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.170</td>\n",
       "      <td>51.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.092</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.368</td>\n",
       "      <td>16.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.341</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.08</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Parameter 1  Parameter 2  Parameter 3  Parameter 4  Parameter 5  \\\n",
       "0           7.4        0.700         0.00          1.9        0.076   \n",
       "1           7.8        0.880         0.00          2.6        0.098   \n",
       "2           7.8        0.760         0.04          2.3        0.092   \n",
       "3          11.2        0.280         0.56          1.9        0.075   \n",
       "4           7.4        0.700         0.00          1.9        0.076   \n",
       "5           7.4        0.660         0.00          1.8        0.075   \n",
       "6           7.9        0.600         0.06          1.6        0.069   \n",
       "7           7.3        0.650         0.00          1.2        0.065   \n",
       "8           7.8        0.580         0.02          2.0        0.073   \n",
       "9           7.5        0.500         0.36          6.1        0.071   \n",
       "10          6.7        0.580         0.08          1.8        0.097   \n",
       "11          7.5        0.500         0.36          6.1        0.071   \n",
       "12          5.6        0.615         0.00          1.6        0.089   \n",
       "13          7.8        0.610         0.29          1.6        0.114   \n",
       "14          8.9        0.620         0.18          3.8        0.176   \n",
       "15          8.9        0.620         0.19          3.9        0.170   \n",
       "16          8.5        0.280         0.56          1.8        0.092   \n",
       "17          8.1        0.560         0.28          1.7        0.368   \n",
       "18          7.4        0.590         0.08          4.4        0.086   \n",
       "19          7.9        0.320         0.51          1.8        0.341   \n",
       "\n",
       "    Parameter 6  Parameter 7  Parameter 8  Parameter 9  Parameter 10  \\\n",
       "0          11.0         34.0       0.9978         3.51          0.56   \n",
       "1          25.0         67.0       0.9968         3.20          0.68   \n",
       "2          15.0         54.0       0.9970         3.26          0.65   \n",
       "3          17.0         60.0       0.9980         3.16          0.58   \n",
       "4          11.0         34.0       0.9978         3.51          0.56   \n",
       "5          13.0         40.0       0.9978         3.51          0.56   \n",
       "6          15.0         59.0       0.9964         3.30          0.46   \n",
       "7          15.0         21.0       0.9946         3.39          0.47   \n",
       "8           9.0         18.0       0.9968         3.36          0.57   \n",
       "9          17.0        102.0       0.9978         3.35          0.80   \n",
       "10         15.0         65.0       0.9959         3.28          0.54   \n",
       "11         17.0        102.0       0.9978         3.35          0.80   \n",
       "12         16.0         59.0       0.9943         3.58          0.52   \n",
       "13          9.0         29.0       0.9974         3.26          1.56   \n",
       "14         52.0        145.0       0.9986         3.16          0.88   \n",
       "15         51.0        148.0       0.9986         3.17          0.93   \n",
       "16         35.0        103.0       0.9969         3.30          0.75   \n",
       "17         16.0         56.0       0.9968         3.11          1.28   \n",
       "18          6.0         29.0       0.9974         3.38          0.50   \n",
       "19         17.0         56.0       0.9969         3.04          1.08   \n",
       "\n",
       "    Parameter 11  Signal_Strength  \n",
       "0            9.4                5  \n",
       "1            9.8                5  \n",
       "2            9.8                5  \n",
       "3            9.8                6  \n",
       "4            9.4                5  \n",
       "5            9.4                5  \n",
       "6            9.4                5  \n",
       "7           10.0                7  \n",
       "8            9.5                7  \n",
       "9           10.5                5  \n",
       "10           9.2                5  \n",
       "11          10.5                5  \n",
       "12           9.9                5  \n",
       "13           9.1                5  \n",
       "14           9.2                5  \n",
       "15           9.2                5  \n",
       "16          10.5                7  \n",
       "17           9.3                5  \n",
       "18           9.0                4  \n",
       "19           9.2                6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.read_csv(\"Signal.csv\", sep = \",\")\n",
    "db.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "serious-sight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.256131</td>\n",
       "      <td>0.671703</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.093705</td>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.113181</td>\n",
       "      <td>0.668047</td>\n",
       "      <td>-0.682978</td>\n",
       "      <td>0.183006</td>\n",
       "      <td>-0.061668</td>\n",
       "      <td>0.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 2</th>\n",
       "      <td>-0.256131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.552496</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>-0.202288</td>\n",
       "      <td>-0.390558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 3</th>\n",
       "      <td>0.671703</td>\n",
       "      <td>-0.552496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>-0.060978</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.364947</td>\n",
       "      <td>-0.541904</td>\n",
       "      <td>0.312770</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.226373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 4</th>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>-0.085652</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>0.013732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 5</th>\n",
       "      <td>0.093705</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>-0.265026</td>\n",
       "      <td>0.371260</td>\n",
       "      <td>-0.221141</td>\n",
       "      <td>-0.128907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 6</th>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>-0.060978</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.069408</td>\n",
       "      <td>-0.050656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 7</th>\n",
       "      <td>-0.113181</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>-0.205654</td>\n",
       "      <td>-0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 8</th>\n",
       "      <td>0.668047</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.364947</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.341699</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.496180</td>\n",
       "      <td>-0.174919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 9</th>\n",
       "      <td>-0.682978</td>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.541904</td>\n",
       "      <td>-0.085652</td>\n",
       "      <td>-0.265026</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>-0.341699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196648</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>-0.057731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 10</th>\n",
       "      <td>0.183006</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>0.312770</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.371260</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.196648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 11</th>\n",
       "      <td>-0.061668</td>\n",
       "      <td>-0.202288</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>-0.221141</td>\n",
       "      <td>-0.069408</td>\n",
       "      <td>-0.205654</td>\n",
       "      <td>-0.496180</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal_Strength</th>\n",
       "      <td>0.124052</td>\n",
       "      <td>-0.390558</td>\n",
       "      <td>0.226373</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>-0.128907</td>\n",
       "      <td>-0.050656</td>\n",
       "      <td>-0.185100</td>\n",
       "      <td>-0.174919</td>\n",
       "      <td>-0.057731</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.476166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameter 1  Parameter 2  Parameter 3  Parameter 4  \\\n",
       "Parameter 1         1.000000    -0.256131     0.671703     0.114777   \n",
       "Parameter 2        -0.256131     1.000000    -0.552496     0.001918   \n",
       "Parameter 3         0.671703    -0.552496     1.000000     0.143577   \n",
       "Parameter 4         0.114777     0.001918     0.143577     1.000000   \n",
       "Parameter 5         0.093705     0.061298     0.203823     0.055610   \n",
       "Parameter 6        -0.153794    -0.010504    -0.060978     0.187049   \n",
       "Parameter 7        -0.113181     0.076470     0.035533     0.203028   \n",
       "Parameter 8         0.668047     0.022026     0.364947     0.355283   \n",
       "Parameter 9        -0.682978     0.234937    -0.541904    -0.085652   \n",
       "Parameter 10        0.183006    -0.260987     0.312770     0.005527   \n",
       "Parameter 11       -0.061668    -0.202288     0.109903     0.042075   \n",
       "Signal_Strength     0.124052    -0.390558     0.226373     0.013732   \n",
       "\n",
       "                 Parameter 5  Parameter 6  Parameter 7  Parameter 8  \\\n",
       "Parameter 1         0.093705    -0.153794    -0.113181     0.668047   \n",
       "Parameter 2         0.061298    -0.010504     0.076470     0.022026   \n",
       "Parameter 3         0.203823    -0.060978     0.035533     0.364947   \n",
       "Parameter 4         0.055610     0.187049     0.203028     0.355283   \n",
       "Parameter 5         1.000000     0.005562     0.047400     0.200632   \n",
       "Parameter 6         0.005562     1.000000     0.667666    -0.021946   \n",
       "Parameter 7         0.047400     0.667666     1.000000     0.071269   \n",
       "Parameter 8         0.200632    -0.021946     0.071269     1.000000   \n",
       "Parameter 9        -0.265026     0.070377    -0.066495    -0.341699   \n",
       "Parameter 10        0.371260     0.051658     0.042947     0.148506   \n",
       "Parameter 11       -0.221141    -0.069408    -0.205654    -0.496180   \n",
       "Signal_Strength    -0.128907    -0.050656    -0.185100    -0.174919   \n",
       "\n",
       "                 Parameter 9  Parameter 10  Parameter 11  Signal_Strength  \n",
       "Parameter 1        -0.682978      0.183006     -0.061668         0.124052  \n",
       "Parameter 2         0.234937     -0.260987     -0.202288        -0.390558  \n",
       "Parameter 3        -0.541904      0.312770      0.109903         0.226373  \n",
       "Parameter 4        -0.085652      0.005527      0.042075         0.013732  \n",
       "Parameter 5        -0.265026      0.371260     -0.221141        -0.128907  \n",
       "Parameter 6         0.070377      0.051658     -0.069408        -0.050656  \n",
       "Parameter 7        -0.066495      0.042947     -0.205654        -0.185100  \n",
       "Parameter 8        -0.341699      0.148506     -0.496180        -0.174919  \n",
       "Parameter 9         1.000000     -0.196648      0.205633        -0.057731  \n",
       "Parameter 10       -0.196648      1.000000      0.093595         0.251397  \n",
       "Parameter 11        0.205633      0.093595      1.000000         0.476166  \n",
       "Signal_Strength    -0.057731      0.251397      0.476166         1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = db.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unavailable-stack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opened-symbol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = db.drop(\"Signal_Strength\", axis = 1)\n",
    "Y = db[\"Signal_Strength\"]\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "literary-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07574445 0.0954888  0.08186864 0.07820201 0.07598253 0.07626899\n",
      " 0.10308744 0.08567481 0.07417384 0.10490629 0.1486022 ]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-straight",
   "metadata": {},
   "source": [
    "Parameter 11 is the most effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faced-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "referenced-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling training and testing data\n",
    "X_Train_S = StandardScaler().fit_transform(X_Train)   \n",
    "\n",
    "X_Test_S = StandardScaler().fit_transform(X_Test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surface-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "Y_Train = to_categorical(Y_Train)\n",
    "Y_Test = to_categorical(Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "optical-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential # Forward prop\n",
    "from keras.layers import Dense, Activation, LeakyReLU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "orange-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1536      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 153       \n",
      "=================================================================\n",
      "Total params: 12,553\n",
      "Trainable params: 12,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model_Classifier = Sequential()\n",
    "\n",
    "#The Input layer. \n",
    "NN_model_Classifier.add(Dense(128, kernel_initializer='normal',input_dim = X_Train.shape[1], activation='relu'))\n",
    "\n",
    "#The Hidden layers. \n",
    "NN_model_Classifier.add(Dense(64, kernel_initializer='normal',activation='relu'))  \n",
    "\n",
    "NN_model_Classifier.add(Dense(32, kernel_initializer='normal'))\n",
    "NN_model_Classifier.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "NN_model_Classifier.add(Dense(16, kernel_initializer='normal'))\n",
    "NN_model_Classifier.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "#The Output layer. \n",
    "NN_model_Classifier.add(Dense(9, kernel_initializer='normal', activation = 'softmax')) \n",
    "\n",
    "#Compiling Network.\n",
    "NN_model_Classifier.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "NN_model_Classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "twenty-south",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1974 - accuracy: 0.2788 - val_loss: 0.1973 - val_accuracy: 0.3812\n",
      "Epoch 2/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.3700 - val_loss: 0.1970 - val_accuracy: 0.4000\n",
      "Epoch 3/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1969 - accuracy: 0.3995 - val_loss: 0.1966 - val_accuracy: 0.4354\n",
      "Epoch 4/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.4584 - val_loss: 0.1959 - val_accuracy: 0.4458\n",
      "Epoch 5/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1954 - accuracy: 0.4576 - val_loss: 0.1943 - val_accuracy: 0.4354\n",
      "Epoch 6/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1933 - accuracy: 0.4316 - val_loss: 0.1907 - val_accuracy: 0.3604\n",
      "Epoch 7/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.4155 - val_loss: 0.1820 - val_accuracy: 0.3604\n",
      "Epoch 8/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.4155 - val_loss: 0.1644 - val_accuracy: 0.3604\n",
      "Epoch 9/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.4155 - val_loss: 0.1426 - val_accuracy: 0.3604\n",
      "Epoch 10/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.4155 - val_loss: 0.1319 - val_accuracy: 0.3604\n",
      "Epoch 11/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.4155 - val_loss: 0.1311 - val_accuracy: 0.3604\n",
      "Epoch 12/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.4155 - val_loss: 0.1338 - val_accuracy: 0.3604\n",
      "Epoch 13/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.4155 - val_loss: 0.1359 - val_accuracy: 0.3604\n",
      "Epoch 14/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.4155 - val_loss: 0.1359 - val_accuracy: 0.3604\n",
      "Epoch 15/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.4155 - val_loss: 0.1355 - val_accuracy: 0.3604\n",
      "Epoch 16/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1267 - accuracy: 0.4155 - val_loss: 0.1340 - val_accuracy: 0.3604\n",
      "Epoch 17/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.4155 - val_loss: 0.1313 - val_accuracy: 0.3604\n",
      "Epoch 18/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.4155 - val_loss: 0.1301 - val_accuracy: 0.3604\n",
      "Epoch 19/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.4155 - val_loss: 0.1294 - val_accuracy: 0.3604\n",
      "Epoch 20/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.4155 - val_loss: 0.1297 - val_accuracy: 0.3604\n",
      "Epoch 21/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1221 - accuracy: 0.4155 - val_loss: 0.1288 - val_accuracy: 0.3604\n",
      "Epoch 22/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.4155 - val_loss: 0.1278 - val_accuracy: 0.3604\n",
      "Epoch 23/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.4155 - val_loss: 0.1275 - val_accuracy: 0.3604\n",
      "Epoch 24/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.4155 - val_loss: 0.1271 - val_accuracy: 0.3604\n",
      "Epoch 25/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.4155 - val_loss: 0.1264 - val_accuracy: 0.3604\n",
      "Epoch 26/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.4155 - val_loss: 0.1255 - val_accuracy: 0.3604\n",
      "Epoch 27/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.4155 - val_loss: 0.1261 - val_accuracy: 0.3604\n",
      "Epoch 28/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.4155 - val_loss: 0.1250 - val_accuracy: 0.3604\n",
      "Epoch 29/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.4155 - val_loss: 0.1236 - val_accuracy: 0.3604\n",
      "Epoch 30/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.4155 - val_loss: 0.1237 - val_accuracy: 0.3604\n",
      "Epoch 31/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.4155 - val_loss: 0.1241 - val_accuracy: 0.3604\n",
      "Epoch 32/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.4155 - val_loss: 0.1224 - val_accuracy: 0.3625\n",
      "Epoch 33/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.4468 - val_loss: 0.1217 - val_accuracy: 0.3875\n",
      "Epoch 34/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.4218 - val_loss: 0.1228 - val_accuracy: 0.3625\n",
      "Epoch 35/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.4540 - val_loss: 0.1202 - val_accuracy: 0.4729\n",
      "Epoch 36/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.5451 - val_loss: 0.1187 - val_accuracy: 0.5021\n",
      "Epoch 37/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.5585 - val_loss: 0.1192 - val_accuracy: 0.4958\n",
      "Epoch 38/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.5621 - val_loss: 0.1159 - val_accuracy: 0.5229\n",
      "Epoch 39/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.5764 - val_loss: 0.1133 - val_accuracy: 0.5312\n",
      "Epoch 40/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.5818 - val_loss: 0.1110 - val_accuracy: 0.5458\n",
      "Epoch 41/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.5907 - val_loss: 0.1049 - val_accuracy: 0.5667\n",
      "Epoch 42/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.5970 - val_loss: 0.1004 - val_accuracy: 0.5604\n",
      "Epoch 43/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.5952 - val_loss: 0.0974 - val_accuracy: 0.5708\n",
      "Epoch 44/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.6023 - val_loss: 0.0979 - val_accuracy: 0.5646\n",
      "Epoch 45/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.5979 - val_loss: 0.0962 - val_accuracy: 0.5688\n",
      "Epoch 46/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0898 - accuracy: 0.6059 - val_loss: 0.0947 - val_accuracy: 0.5813\n",
      "Epoch 47/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 0.6068 - val_loss: 0.0951 - val_accuracy: 0.5813\n",
      "Epoch 48/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.6050 - val_loss: 0.0956 - val_accuracy: 0.5708\n",
      "Epoch 49/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.6068 - val_loss: 0.0952 - val_accuracy: 0.5750\n",
      "Epoch 50/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.6077 - val_loss: 0.0949 - val_accuracy: 0.5729\n",
      "Epoch 51/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.6139 - val_loss: 0.0947 - val_accuracy: 0.5771\n",
      "Epoch 52/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.6166 - val_loss: 0.0947 - val_accuracy: 0.5750\n",
      "Epoch 53/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.6193 - val_loss: 0.0950 - val_accuracy: 0.5729\n",
      "Epoch 54/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.6175 - val_loss: 0.0947 - val_accuracy: 0.5729\n",
      "Epoch 55/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.6211 - val_loss: 0.0949 - val_accuracy: 0.5771\n",
      "Epoch 56/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.6220 - val_loss: 0.0946 - val_accuracy: 0.5750\n",
      "Epoch 57/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.6211 - val_loss: 0.0947 - val_accuracy: 0.5750\n",
      "Epoch 58/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.6220 - val_loss: 0.0948 - val_accuracy: 0.5729\n",
      "Epoch 59/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.6220 - val_loss: 0.0948 - val_accuracy: 0.5729\n",
      "Epoch 60/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.6238 - val_loss: 0.0949 - val_accuracy: 0.5750\n",
      "Epoch 61/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.6247 - val_loss: 0.0949 - val_accuracy: 0.5729\n",
      "Epoch 62/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.6256 - val_loss: 0.0951 - val_accuracy: 0.5729\n",
      "Epoch 63/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.6273 - val_loss: 0.0948 - val_accuracy: 0.5708\n",
      "Epoch 64/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.6291 - val_loss: 0.0946 - val_accuracy: 0.5771\n",
      "Epoch 65/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.6291 - val_loss: 0.0943 - val_accuracy: 0.5750\n",
      "Epoch 66/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.6300 - val_loss: 0.0942 - val_accuracy: 0.5771\n",
      "Epoch 67/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.6291 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 68/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.6300 - val_loss: 0.0942 - val_accuracy: 0.5771\n",
      "Epoch 69/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.6309 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 70/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.6300 - val_loss: 0.0941 - val_accuracy: 0.5792\n",
      "Epoch 71/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.6300 - val_loss: 0.0941 - val_accuracy: 0.5792\n",
      "Epoch 72/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.64 - 0s 5ms/step - loss: 0.0825 - accuracy: 0.6300 - val_loss: 0.0942 - val_accuracy: 0.5729\n",
      "Epoch 73/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.6309 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 74/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.6300 - val_loss: 0.0939 - val_accuracy: 0.5792\n",
      "Epoch 75/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.6309 - val_loss: 0.0941 - val_accuracy: 0.5729\n",
      "Epoch 76/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.6309 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 77/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.6309 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 78/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.6318 - val_loss: 0.0940 - val_accuracy: 0.5792\n",
      "Epoch 79/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.6318 - val_loss: 0.0940 - val_accuracy: 0.5792\n",
      "Epoch 80/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.6327 - val_loss: 0.0940 - val_accuracy: 0.5792\n",
      "Epoch 81/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.6318 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 82/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0819 - accuracy: 0.6327 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 83/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0819 - accuracy: 0.6327 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 84/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.6327 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 85/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.6327 - val_loss: 0.0940 - val_accuracy: 0.5792\n",
      "Epoch 86/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.6327 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 87/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 88/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.6336 - val_loss: 0.0939 - val_accuracy: 0.5771\n",
      "Epoch 89/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 90/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 91/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 92/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 93/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 94/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.6336 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 95/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 96/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 97/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.6336 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 98/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.6336 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 99/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.6336 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 100/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.6336 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 101/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.6336 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 102/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.6336 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 103/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.6336 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 104/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5771\n",
      "Epoch 105/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 106/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 107/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5750\n",
      "Epoch 108/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 109/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5750\n",
      "Epoch 110/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 111/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 112/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5729\n",
      "Epoch 113/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5750\n",
      "Epoch 114/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5750\n",
      "Epoch 115/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5729\n",
      "Epoch 116/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5750\n",
      "Epoch 117/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5729\n",
      "Epoch 118/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5729\n",
      "Epoch 119/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5729\n",
      "Epoch 120/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 121/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5729\n",
      "Epoch 122/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5729\n",
      "Epoch 123/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5729\n",
      "Epoch 124/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5729\n",
      "Epoch 125/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5729\n",
      "Epoch 126/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5729\n",
      "Epoch 127/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5729\n",
      "Epoch 128/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0940 - val_accuracy: 0.5729\n",
      "Epoch 129/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.63 - 0s 4ms/step - loss: 0.0812 - accuracy: 0.6345 - val_loss: 0.0938 - val_accuracy: 0.5771\n",
      "Epoch 130/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0936 - val_accuracy: 0.5771\n",
      "Epoch 131/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 132/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0945 - val_accuracy: 0.5729\n",
      "Epoch 133/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0947 - val_accuracy: 0.5708\n",
      "Epoch 134/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0946 - val_accuracy: 0.5729\n",
      "Epoch 135/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 136/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0943 - val_accuracy: 0.5750\n",
      "Epoch 137/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0943 - val_accuracy: 0.5750\n",
      "Epoch 138/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 139/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 140/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 141/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.6345 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 142/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.6345 - val_loss: 0.0941 - val_accuracy: 0.5750\n",
      "Epoch 143/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.6336 - val_loss: 0.0937 - val_accuracy: 0.5792\n",
      "Epoch 144/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0944 - val_accuracy: 0.5750\n",
      "Epoch 145/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0943 - val_accuracy: 0.5750\n",
      "Epoch 146/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0941 - val_accuracy: 0.5771\n",
      "Epoch 147/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 148/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.6354 - val_loss: 0.0944 - val_accuracy: 0.5750\n",
      "Epoch 149/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.6354 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 150/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0946 - val_accuracy: 0.5750\n",
      "Epoch 151/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0946 - val_accuracy: 0.5750\n",
      "Epoch 152/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0943 - val_accuracy: 0.5750\n",
      "Epoch 153/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0943 - val_accuracy: 0.5750\n",
      "Epoch 154/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 155/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0944 - val_accuracy: 0.5750\n",
      "Epoch 156/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0944 - val_accuracy: 0.5729\n",
      "Epoch 157/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0943 - val_accuracy: 0.5729\n",
      "Epoch 158/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0944 - val_accuracy: 0.5750\n",
      "Epoch 159/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 160/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0944 - val_accuracy: 0.5750\n",
      "Epoch 161/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0943 - val_accuracy: 0.5750\n",
      "Epoch 162/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0940 - val_accuracy: 0.5750\n",
      "Epoch 163/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 164/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.6354 - val_loss: 0.0945 - val_accuracy: 0.5729\n",
      "Epoch 165/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0938 - val_accuracy: 0.5771\n",
      "Epoch 166/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 167/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 168/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 169/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.6354 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 170/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.6363 - val_loss: 0.0940 - val_accuracy: 0.5771\n",
      "Epoch 171/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6363 - val_loss: 0.0944 - val_accuracy: 0.5750\n",
      "Epoch 172/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.6363 - val_loss: 0.0944 - val_accuracy: 0.5750\n",
      "Epoch 173/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0946 - val_accuracy: 0.5729\n",
      "Epoch 174/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0946 - val_accuracy: 0.5750\n",
      "Epoch 175/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 176/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0942 - val_accuracy: 0.5750\n",
      "Epoch 177/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6363 - val_loss: 0.0944 - val_accuracy: 0.5750\n",
      "Epoch 178/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.6354 - val_loss: 0.0946 - val_accuracy: 0.5750\n",
      "Epoch 179/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0946 - val_accuracy: 0.5729\n",
      "Epoch 180/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.6363 - val_loss: 0.0946 - val_accuracy: 0.5729\n",
      "Epoch 181/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 182/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5729\n",
      "Epoch 183/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5729\n",
      "Epoch 184/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 185/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 186/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 187/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 188/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 189/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 190/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 191/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 192/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 193/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 194/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 195/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 196/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 197/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 198/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 199/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 200/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 201/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 202/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 203/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 204/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 205/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 206/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 207/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 208/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 209/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 210/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 211/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 212/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 213/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 214/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 215/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 216/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 217/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 218/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 219/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 220/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 221/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 222/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 223/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 224/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 225/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 226/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 227/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 228/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 229/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 230/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 231/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 232/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 233/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 234/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 235/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 236/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.68 - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 237/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 238/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 239/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 240/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 241/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 242/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 243/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 244/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 245/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 246/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 247/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 248/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 249/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 250/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 251/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 252/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 253/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 254/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 255/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 256/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 257/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 258/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 259/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 260/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 261/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 262/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 263/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 264/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 265/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 266/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 267/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 268/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 269/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 270/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 271/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.66 - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 272/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 273/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 274/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 275/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 276/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 277/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 278/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 279/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 280/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 281/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 282/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 283/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 284/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 285/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 286/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 287/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 288/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 289/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 290/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 291/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 292/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 293/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 294/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 295/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 296/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 297/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 298/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 299/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 300/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 301/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 302/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 303/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 304/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 305/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 306/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 307/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 308/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 309/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 310/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 311/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 312/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 313/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 314/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 315/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 316/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 317/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 318/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 319/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 320/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 321/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 322/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 323/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 324/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 325/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 326/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.65 - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 327/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 328/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 329/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 330/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 331/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 332/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 333/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 334/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 335/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 336/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 337/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 338/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 339/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 340/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 341/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 342/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 343/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 344/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 345/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 346/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 347/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 348/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 349/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n",
      "Epoch 350/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.6363 - val_loss: 0.0945 - val_accuracy: 0.5750\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "EPOCH = 350\n",
    "Network_Classifier=NN_model_Classifier.fit(X_Train_S, Y_Train, validation_data=(X_Test_S,Y_Test), epochs=EPOCH, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fresh-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = Network_Classifier.history['loss']\n",
    "loss_val = Network_Classifier.history['val_loss']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, loss_train, 'r', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-helen",
   "metadata": {},
   "source": [
    " Pickling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blond-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "C_json = NN_model_Classifier.to_json()\n",
    "with open(\"Classifier_model.json\", \"w\") as json_file:\n",
    "    json_file.write(C_json)\n",
    "\n",
    "NN_model_Classifier.save_weights(\"Classifier_model.h5\")\n",
    "print(\"Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
