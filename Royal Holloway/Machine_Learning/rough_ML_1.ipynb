{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "scenic-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Random_state = 3006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brilliant-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "ionosphere_data = np.genfromtxt(\"ionosphere.txt\", delimiter=',', names=True, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hundred-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data\n",
    "\n",
    "iris_X = iris_data['data']\n",
    "iris_y = iris_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formed-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "ionosphere_data\n",
    "list_data = [list(x) for x in ionosphere_data]\n",
    "iono_X = []\n",
    "iono_y = []\n",
    "for i,d in enumerate(list_data):\n",
    "    iono_X.append([x for j,x in enumerate(d) if j!=len(d)-1])\n",
    "    iono_y.append([x for j,x in enumerate(d) if j==len(d)-1])\n",
    "\n",
    "iono_X = np.array(iono_X)\n",
    "iono_y = np.hstack(iono_y)\n",
    "iono_y = np.where(iono_y == 1, 1, 0) #converting to 0 and 1 for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sitting-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_it(list_to_sort):    \n",
    "    try:\n",
    "        for i in range(len(list_to_sort)):\n",
    "            for j in range(len(list_to_sort) - 1):\n",
    "                if list_to_sort[j] > list_to_sort[j+1]:\n",
    "                    list_to_sort[j], list_to_sort[j + 1] = list_to_sort[j + 1], list_to_sort[j]\n",
    "                \n",
    "        return list_to_sort\n",
    "    except:\n",
    "        print(sys.exc_info())\n",
    "\n",
    "def run_prediction(X, y, test_size=0.3, train_size=0.7, random_state=Random_state, k=1):\n",
    "    \n",
    "    if(test_size+train_size > 1 or test_size+train_size < 0):\n",
    "        print(\"The sum of test_size and train_size should be between 0 and 1\")\n",
    "        return\n",
    "    \n",
    "    prediction = {\"predicted_list\" : [], \"accuracy\" : 0}\n",
    "    \n",
    "    try:\n",
    "        # splitting test train data\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size, random_state=Random_state)\n",
    "\n",
    "        predicted_list = []\n",
    "    \n",
    "        # training on X_train, y_train by calculating Euclidean distances\n",
    "        for d in range(len(X_test)):\n",
    "            eucl_distances = []\n",
    "            for i in range(len(X_train)):\n",
    "                #eucl_distances.append([np.sqrt(np.sum(np.power(X_test[d,:] - X_train[i,:], 2))), i])\n",
    "                eucl_distances.append([np.linalg.norm(X_test[d,:] - X_train[i,:]), i]) #used linalg for faster calculation time\n",
    "                \n",
    "            eucl_distances = sort_it(eucl_distances)\n",
    "            #print(eucl_distances)\n",
    "    \n",
    "            targets = [y_train[eucl_distances[i][1]] for i in range(k)]\n",
    "            #print(targets)\n",
    "        \n",
    "            predicted_list.append(max(targets, key=targets.count))\n",
    "\n",
    "        #print(predicted_list)\n",
    "        prediction['predicted_list'] = predicted_list\n",
    "        prediction['accuracy'] = np.mean(prediction['predicted_list'] == y_test)\n",
    "        return prediction\n",
    "    \n",
    "    except:\n",
    "        print(sys.exc_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "relevant-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_list': [0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 0, 2, 1, 1, 2, 2, 1, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0], 'accuracy': 0.9555555555555556}\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    nn = run_prediction(iris_X, iris_y, test_size=0.3,train_size=0.7, random_state=Random_state, k=1)\n",
    "    print(nn)\n",
    "except:\n",
    "    print(sys.exc_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "subjective-manchester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For iris dataset, The average false p-value : 0.028616352201257873 \n",
      "The accuracy of prediction : 1.0 \n",
      "The test error rate is : 0.0\n"
     ]
    }
   ],
   "source": [
    "conformal(iris_X, iris_y, \"iris dataset\", test_size=0.3,train_size=0.7, random_state=107)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "romantic-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ionosphere dataset, The average false p-value : 0.030845481049562678 \n",
      "The accuracy of prediction : 0.9142857142857143 \n",
      "The test error rate is : 0.08571428571428574\n"
     ]
    }
   ],
   "source": [
    "conformal(iono_X, iono_y, \"ionosphere dataset\", test_size=0.3,train_size=0.7, random_state=107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "complicated-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition along with parameters\n",
    "def conformity_score_Common(X_train,Y_train,X_test,Y_test,i,j,labels):\n",
    "    \n",
    "    import math\n",
    "    # concatenating (X,y) of training set\n",
    "    x_train_concat=np.concatenate((X_train,y_train[:,None]),axis=1)\n",
    "    # concatenating (X,y) of one test set per function\n",
    "    x_test_add=np.concatenate((X_test[i:i+1,],labels[j:j+1,None]),axis=1)\n",
    "    # concatenating (X,y) of all training set and one test set\n",
    "    x_train_test_concat=np.concatenate((x_train_concat,x_test_add))\n",
    "    # concatenating y of training set and one test set\n",
    "    y_concat=np.concatenate((y_train,labels[j:j+1]))\n",
    "    # assign size of CF_score array\n",
    "    CF_score=np.zeros(x_train_test_concat.shape[0])\n",
    "    # iterate through each (x,y) of set and find distance\n",
    "    for k in range(x_train_test_concat.shape[0]):\n",
    "        arr_same=[]\n",
    "        arr_diff=[]\n",
    "        for l in range(x_train_test_concat.shape[0]):\n",
    "            if k!=l:\n",
    "                # find distance between sample of same class\n",
    "                if x_train_test_concat[k,-1]==y_concat[l]:\n",
    "                    arr_same.append(la.norm(x_train_test_concat[k,:-1]-x_train_test_concat[l,:-1]))\n",
    "                # find distance between sample of different class\n",
    "                else:\n",
    "                    arr_diff.append(la.norm(x_train_test_concat[k,:-1]-x_train_test_concat[l,:-1]))\n",
    "    # exception handling for ZeroDivisionError\n",
    "    # using formula -(distance between nearest sample of same class)/(distance between nearest sample of diff class)\n",
    "        try:\n",
    "            CF_score[k]=(min(arr_diff)/min(arr_same)) \n",
    "        except ZeroDivisionError:\n",
    "            CF_score[k]=np.inf\n",
    "    return CF_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "expensive-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating p value of each CF_score array\n",
    "def p_value(CF_score):\n",
    "    count=0\n",
    "    for m in range(CF_score.shape[0]):\n",
    "    \n",
    "        if CF_score[m]<=CF_score[-1]:\n",
    "            count+=1\n",
    "    p_value=(count/CF_score.shape[0])\n",
    "    return p_value\n",
    "import numpy as np\n",
    "p_value(np.array([1,2,3,6,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "internal-survival",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-0e105b903823>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlabels_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mp_value_array_for_each\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# calculation of p_value of each test sample for every label\n",
    "def p_value_array_for_each(X_train,X_test,y_train,y_test,labels):\n",
    "    \n",
    "    labels_array=np.zeros((X_test.shape[0],labels.shape[0]))\n",
    "    for ii in range(X_test.shape[0]):\n",
    "        for jj in range(labels.shape[0]):\n",
    "            labels_array[ii,jj]=p_value(conformity_score_Common(X_train,y_train,X_test,y_test,ii,jj,labels))\n",
    "    return labels_array \n",
    "\n",
    "p_value_array_for_each(X_train,X_test,y_train,y_test,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "naval-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculation of average false p_value\n",
    "def average_false_pvalue_CF(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    labels=np.unique(y_train)\n",
    "    p_value_array_FP=p_value_array_for_each(X_train,X_test,y_train,y_test,labels)\n",
    "    sum=0\n",
    "    for ii in range(p_value_array_FP.shape[0]):\n",
    "        for jj in range(labels.shape[0]):\n",
    "            # summation of false_pvalues \n",
    "            if labels[jj]!=y_test[ii]:\n",
    "                sum+=p_value_array_FP[ii,jj]\n",
    "    # average of false_p_value\n",
    "    return (sum/(X_test.shape[0]*(labels.shape[0]-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-genealogy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
