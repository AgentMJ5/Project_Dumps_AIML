{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civilian-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complimentary-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.089</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.114</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.176</td>\n",
       "      <td>52.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.170</td>\n",
       "      <td>51.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.092</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.368</td>\n",
       "      <td>16.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.341</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.08</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Parameter 1  Parameter 2  Parameter 3  Parameter 4  Parameter 5  \\\n",
       "0           7.4        0.700         0.00          1.9        0.076   \n",
       "1           7.8        0.880         0.00          2.6        0.098   \n",
       "2           7.8        0.760         0.04          2.3        0.092   \n",
       "3          11.2        0.280         0.56          1.9        0.075   \n",
       "4           7.4        0.700         0.00          1.9        0.076   \n",
       "5           7.4        0.660         0.00          1.8        0.075   \n",
       "6           7.9        0.600         0.06          1.6        0.069   \n",
       "7           7.3        0.650         0.00          1.2        0.065   \n",
       "8           7.8        0.580         0.02          2.0        0.073   \n",
       "9           7.5        0.500         0.36          6.1        0.071   \n",
       "10          6.7        0.580         0.08          1.8        0.097   \n",
       "11          7.5        0.500         0.36          6.1        0.071   \n",
       "12          5.6        0.615         0.00          1.6        0.089   \n",
       "13          7.8        0.610         0.29          1.6        0.114   \n",
       "14          8.9        0.620         0.18          3.8        0.176   \n",
       "15          8.9        0.620         0.19          3.9        0.170   \n",
       "16          8.5        0.280         0.56          1.8        0.092   \n",
       "17          8.1        0.560         0.28          1.7        0.368   \n",
       "18          7.4        0.590         0.08          4.4        0.086   \n",
       "19          7.9        0.320         0.51          1.8        0.341   \n",
       "\n",
       "    Parameter 6  Parameter 7  Parameter 8  Parameter 9  Parameter 10  \\\n",
       "0          11.0         34.0       0.9978         3.51          0.56   \n",
       "1          25.0         67.0       0.9968         3.20          0.68   \n",
       "2          15.0         54.0       0.9970         3.26          0.65   \n",
       "3          17.0         60.0       0.9980         3.16          0.58   \n",
       "4          11.0         34.0       0.9978         3.51          0.56   \n",
       "5          13.0         40.0       0.9978         3.51          0.56   \n",
       "6          15.0         59.0       0.9964         3.30          0.46   \n",
       "7          15.0         21.0       0.9946         3.39          0.47   \n",
       "8           9.0         18.0       0.9968         3.36          0.57   \n",
       "9          17.0        102.0       0.9978         3.35          0.80   \n",
       "10         15.0         65.0       0.9959         3.28          0.54   \n",
       "11         17.0        102.0       0.9978         3.35          0.80   \n",
       "12         16.0         59.0       0.9943         3.58          0.52   \n",
       "13          9.0         29.0       0.9974         3.26          1.56   \n",
       "14         52.0        145.0       0.9986         3.16          0.88   \n",
       "15         51.0        148.0       0.9986         3.17          0.93   \n",
       "16         35.0        103.0       0.9969         3.30          0.75   \n",
       "17         16.0         56.0       0.9968         3.11          1.28   \n",
       "18          6.0         29.0       0.9974         3.38          0.50   \n",
       "19         17.0         56.0       0.9969         3.04          1.08   \n",
       "\n",
       "    Parameter 11  Signal_Strength  \n",
       "0            9.4                5  \n",
       "1            9.8                5  \n",
       "2            9.8                5  \n",
       "3            9.8                6  \n",
       "4            9.4                5  \n",
       "5            9.4                5  \n",
       "6            9.4                5  \n",
       "7           10.0                7  \n",
       "8            9.5                7  \n",
       "9           10.5                5  \n",
       "10           9.2                5  \n",
       "11          10.5                5  \n",
       "12           9.9                5  \n",
       "13           9.1                5  \n",
       "14           9.2                5  \n",
       "15           9.2                5  \n",
       "16          10.5                7  \n",
       "17           9.3                5  \n",
       "18           9.0                4  \n",
       "19           9.2                6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.read_csv(\"Signal.csv\", sep = \",\")\n",
    "db.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "official-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n"
     ]
    }
   ],
   "source": [
    "print(db.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sustainable-income",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter 1        0\n",
       "Parameter 2        0\n",
       "Parameter 3        0\n",
       "Parameter 4        0\n",
       "Parameter 5        0\n",
       "Parameter 6        0\n",
       "Parameter 7        0\n",
       "Parameter 8        0\n",
       "Parameter 9        0\n",
       "Parameter 10       0\n",
       "Parameter 11       0\n",
       "Signal_Strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for Null values\n",
    "db.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extra-wages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter 1</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>8.319637</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>7.1000</td>\n",
       "      <td>7.90000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>15.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 2</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 3</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 4</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>2.20000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>15.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 5</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.07900</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.61100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 6</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>72.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 7</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>289.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 8</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.99007</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>1.00369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 9</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>2.74000</td>\n",
       "      <td>3.2100</td>\n",
       "      <td>3.31000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 10</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.62000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 11</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>8.40000</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>10.20000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>14.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal_Strength</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>5.636023</td>\n",
       "      <td>0.807569</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count       mean        std      min      25%       50%  \\\n",
       "Parameter 1      1599.0   8.319637   1.741096  4.60000   7.1000   7.90000   \n",
       "Parameter 2      1599.0   0.527821   0.179060  0.12000   0.3900   0.52000   \n",
       "Parameter 3      1599.0   0.270976   0.194801  0.00000   0.0900   0.26000   \n",
       "Parameter 4      1599.0   2.538806   1.409928  0.90000   1.9000   2.20000   \n",
       "Parameter 5      1599.0   0.087467   0.047065  0.01200   0.0700   0.07900   \n",
       "Parameter 6      1599.0  15.874922  10.460157  1.00000   7.0000  14.00000   \n",
       "Parameter 7      1599.0  46.467792  32.895324  6.00000  22.0000  38.00000   \n",
       "Parameter 8      1599.0   0.996747   0.001887  0.99007   0.9956   0.99675   \n",
       "Parameter 9      1599.0   3.311113   0.154386  2.74000   3.2100   3.31000   \n",
       "Parameter 10     1599.0   0.658149   0.169507  0.33000   0.5500   0.62000   \n",
       "Parameter 11     1599.0  10.422983   1.065668  8.40000   9.5000  10.20000   \n",
       "Signal_Strength  1599.0   5.636023   0.807569  3.00000   5.0000   6.00000   \n",
       "\n",
       "                       75%        max  \n",
       "Parameter 1       9.200000   15.90000  \n",
       "Parameter 2       0.640000    1.58000  \n",
       "Parameter 3       0.420000    1.00000  \n",
       "Parameter 4       2.600000   15.50000  \n",
       "Parameter 5       0.090000    0.61100  \n",
       "Parameter 6      21.000000   72.00000  \n",
       "Parameter 7      62.000000  289.00000  \n",
       "Parameter 8       0.997835    1.00369  \n",
       "Parameter 9       3.400000    4.01000  \n",
       "Parameter 10      0.730000    2.00000  \n",
       "Parameter 11     11.100000   14.90000  \n",
       "Signal_Strength   6.000000    8.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "attractive-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.256131</td>\n",
       "      <td>0.671703</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.093705</td>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.113181</td>\n",
       "      <td>0.668047</td>\n",
       "      <td>-0.682978</td>\n",
       "      <td>0.183006</td>\n",
       "      <td>-0.061668</td>\n",
       "      <td>0.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 2</th>\n",
       "      <td>-0.256131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.552496</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>-0.202288</td>\n",
       "      <td>-0.390558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 3</th>\n",
       "      <td>0.671703</td>\n",
       "      <td>-0.552496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>-0.060978</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.364947</td>\n",
       "      <td>-0.541904</td>\n",
       "      <td>0.312770</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.226373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 4</th>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>-0.085652</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>0.013732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 5</th>\n",
       "      <td>0.093705</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>-0.265026</td>\n",
       "      <td>0.371260</td>\n",
       "      <td>-0.221141</td>\n",
       "      <td>-0.128907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 6</th>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>-0.060978</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.069408</td>\n",
       "      <td>-0.050656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 7</th>\n",
       "      <td>-0.113181</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>-0.205654</td>\n",
       "      <td>-0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 8</th>\n",
       "      <td>0.668047</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.364947</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.341699</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.496180</td>\n",
       "      <td>-0.174919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 9</th>\n",
       "      <td>-0.682978</td>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.541904</td>\n",
       "      <td>-0.085652</td>\n",
       "      <td>-0.265026</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>-0.341699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196648</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>-0.057731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 10</th>\n",
       "      <td>0.183006</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>0.312770</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.371260</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.196648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 11</th>\n",
       "      <td>-0.061668</td>\n",
       "      <td>-0.202288</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>-0.221141</td>\n",
       "      <td>-0.069408</td>\n",
       "      <td>-0.205654</td>\n",
       "      <td>-0.496180</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal_Strength</th>\n",
       "      <td>0.124052</td>\n",
       "      <td>-0.390558</td>\n",
       "      <td>0.226373</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>-0.128907</td>\n",
       "      <td>-0.050656</td>\n",
       "      <td>-0.185100</td>\n",
       "      <td>-0.174919</td>\n",
       "      <td>-0.057731</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.476166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameter 1  Parameter 2  Parameter 3  Parameter 4  \\\n",
       "Parameter 1         1.000000    -0.256131     0.671703     0.114777   \n",
       "Parameter 2        -0.256131     1.000000    -0.552496     0.001918   \n",
       "Parameter 3         0.671703    -0.552496     1.000000     0.143577   \n",
       "Parameter 4         0.114777     0.001918     0.143577     1.000000   \n",
       "Parameter 5         0.093705     0.061298     0.203823     0.055610   \n",
       "Parameter 6        -0.153794    -0.010504    -0.060978     0.187049   \n",
       "Parameter 7        -0.113181     0.076470     0.035533     0.203028   \n",
       "Parameter 8         0.668047     0.022026     0.364947     0.355283   \n",
       "Parameter 9        -0.682978     0.234937    -0.541904    -0.085652   \n",
       "Parameter 10        0.183006    -0.260987     0.312770     0.005527   \n",
       "Parameter 11       -0.061668    -0.202288     0.109903     0.042075   \n",
       "Signal_Strength     0.124052    -0.390558     0.226373     0.013732   \n",
       "\n",
       "                 Parameter 5  Parameter 6  Parameter 7  Parameter 8  \\\n",
       "Parameter 1         0.093705    -0.153794    -0.113181     0.668047   \n",
       "Parameter 2         0.061298    -0.010504     0.076470     0.022026   \n",
       "Parameter 3         0.203823    -0.060978     0.035533     0.364947   \n",
       "Parameter 4         0.055610     0.187049     0.203028     0.355283   \n",
       "Parameter 5         1.000000     0.005562     0.047400     0.200632   \n",
       "Parameter 6         0.005562     1.000000     0.667666    -0.021946   \n",
       "Parameter 7         0.047400     0.667666     1.000000     0.071269   \n",
       "Parameter 8         0.200632    -0.021946     0.071269     1.000000   \n",
       "Parameter 9        -0.265026     0.070377    -0.066495    -0.341699   \n",
       "Parameter 10        0.371260     0.051658     0.042947     0.148506   \n",
       "Parameter 11       -0.221141    -0.069408    -0.205654    -0.496180   \n",
       "Signal_Strength    -0.128907    -0.050656    -0.185100    -0.174919   \n",
       "\n",
       "                 Parameter 9  Parameter 10  Parameter 11  Signal_Strength  \n",
       "Parameter 1        -0.682978      0.183006     -0.061668         0.124052  \n",
       "Parameter 2         0.234937     -0.260987     -0.202288        -0.390558  \n",
       "Parameter 3        -0.541904      0.312770      0.109903         0.226373  \n",
       "Parameter 4        -0.085652      0.005527      0.042075         0.013732  \n",
       "Parameter 5        -0.265026      0.371260     -0.221141        -0.128907  \n",
       "Parameter 6         0.070377      0.051658     -0.069408        -0.050656  \n",
       "Parameter 7        -0.066495      0.042947     -0.205654        -0.185100  \n",
       "Parameter 8        -0.341699      0.148506     -0.496180        -0.174919  \n",
       "Parameter 9         1.000000     -0.196648      0.205633        -0.057731  \n",
       "Parameter 10       -0.196648      1.000000      0.093595         0.251397  \n",
       "Parameter 11        0.205633      0.093595      1.000000         0.476166  \n",
       "Signal_Strength    -0.057731      0.251397      0.476166         1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = db.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "banned-haven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAFBCAYAAADJzoCJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAy40lEQVR4nO3debwcZZ3v8c83CRkYAgRkT9iEgCA7GDaBCKKAynIHlVEUHLjAHVFwxgWQO8RZBHX0OggMg4qC4gKIGBWRfVFAwx4IIiFsIQgDIyBrknN+94+qk3Q6fc7pPlXP6arO9+2rXumurvOtp5tjP6eqnnp+igjMzMyqbEy3G2BmZjYcd1ZmZlZ57qzMzKzy3FmZmVnlubMyM7PKc2dlZmaV587KzMzaJukCSc9Kun+Q1yXpLElzJN0naccy9uvOyszMOvFdYP8hXj8AmJIvxwL/WcZO3VmZmVnbIuJm4H+G2ORg4KLI3A5MlLRe0f2OKxpgnVv43Nwk04Yct/NnU8Ryzhc2S5ILMPNzjyTJXRhp/g67YaWxSXIBVk7U5pOmr58kd5XjLk6SC3DHejslyf1N/6pJcrdb+HqSXIA9/3SZimZ08p0zfq1NjyM7IhpwfkSc38HuJgFPNjyfl697uoOMZbizMjOzxfKOqZPOqVmrzrXwH+jurMzMel1/32jubR6wQcPzycD8oqG+ZmVm1uv6FrW/FDcD+Gg+KnBX4MWIKHQKEHxkZWbW8yL6S8uS9ENgGrCmpHnA6cAK2X7iPOBK4EBgDvAq8LEy9uvOysys1/WX11lFxN8O83oAHy9th7lROw0oqU/SPZLul3SppL8erX0P0aZpknYvIecqSS9I+kUZ7TIzK1X0t79U1Ghes3otIraPiK2BBcDx7fyQpJRHf9OAjjqrQdrzFeAjZTTIzKx0/X3tLxXVrdOAtwDbSnofcBowHnge+HBEPCNpOrA+sDHwnKRTge8BK+c/f0JE3CppGvAF4Blge+ByYBZwIrAScEhEPCJpLeA8YMP8508CniLrMPskHQF8AvhD83YR8dvm9gAfanwzEXFd3hYzs+qp8BFTu0a9s8qPTA4ArgJ+A+waESHpGOCzwD/mm+4EvD0iXstPGe4XEa9LmgL8ENg53247YEuyO6rnAt+KiKmSTiTrgE4C/gP4fxHxG0kbAr+OiC0lnQe8HBH/nrftB83b5dlLtWeE7/tY8hvtzv3qv3LMR4c87WtmVpooZ5RfV41mZ7WSpHvyx7cA3wa2AH6cT8UxHni0YfsZDR3DCsDZkrYH+oDNG7abOTAsUtIjwNX5+lnAO/LH7wS2khbfq7aqpFVatHGo7WaMtKOCpW+0SzWDhZlZSyUOsOiW0eysXouI7RtXSPoG8LWImJGfRpve8PIrDY8/RXaqbzuy62yNc5u80fC4v+F5P0ve3xhgt+bOpqFToo3tXmne2MysFnrgNGC3bwpejezaEcCRw2z3dGQ3C3wE6HSCtquBEwae5EdoAH8BVmljOzOz+uqBARbd7qymA5dKuoVs4MJgzgWOlHQ72SnATo9yPgnsnNdWmc2SkYg/Bw7Nh9TvOcR2Q8rbfymwr6R5kt7dYfvMzNLpgaHro3YaMCImtFj3M+BnLdZPb3r+MLBtw6pT8vU3Ajc2bDet4fHi1yLiOeCDLfbzx6ZcBtluevO6ptf3HOp1M7Ou8gALMzOrPA+wMDOzqouo7rWodrmzMjPrdRW+FtUud1ZdkKqi73/d8eUkuZtufnCSXIAzVtwuSe7EvjR/SW6+MN2YpLUXpbmu8ItTnxp+oxGYvek2SXIBznxtfJLc1cam+Yx/Gi8lyQW4rowQnwY0M7PK85GVmZlVXt/CbregMHdWZma9zqcBzcys8nrgNGC3Z7AwM7PU+vvbX4YhaX9JD0maI+nkFq+vJunnku6V9ICkUsrau1JwwUrBkraXdFv+H+U+ScvMgGFm1lUldVaSxgLnkJV52gr4W0lbNW32cWB2RGxHVuD2q5IKD+90peDilYJfBT4aEW8F9ge+LmliKa0zMytB9C1sexnGVGBORMyNiAXAj4Dme1sCWEVZuYoJZLUGC98z4ErBBSsF5/MLDjyeL+lZYC3ghUKfkJlZWTq4ZtVYKDZ3fl6PD2AS8GTDa/OAXZoizgZmAPPJqlp8MK+YUYgrBZdYKVjSVLKO95Gin5OZWWk6GA3YWCi2hWWKAJIdSTV6N3APsA+wKXCNpFsiit057UrBSxtxpeD8PXwPOLLVXxGNf63svsYObLHKmweLMjMrV3mjAecBGzQ8n0x2BNXoY8CZERHAHEmPAm8Bfl9kx64UvLQRVQqWtCrwS+C0iLi91TaNf6383caHuay9mY2e8u6zmglMkbQJ2aWUw2m4LJJ7AtgXuEXSOmQHJXOL7rjbQ9drXyk4H+XyU+CiiLi0w3aZmaVXUvHFiFhE9h35a+BB4JKIeEDS8ZIGBs39C7C7pFlkUxt+Lq8pWEi3bwqeTlYp+CngdmCTQbY7F/iJpPcDNzCySsHnSLqP7D3fTDa44ufAZZIOJru+Ndh2Q/kAsBfwJklH5euOioh7OmyjmVkaJU6SHBFXAlc2rTuv4fF84F2l7TDnSsEFKwVHxPeB7w/2uplZ1/XADBbdPrIyM7PUPDegmZlVno+szMys8nxkZSNxzhc2S5KbqqLvI39c5rJiae7c9tNJciesvCBJ7qMLJybJBZigNINz99lxXpLcnW9/IUkuwK1brpEk96GH10ySe/zqnQ5QHmU+sjIzs8orcTRgt7izMjPrdVH/eQjcWZmZ9TpfszIzs8pzZ2VmZpXnARbtk9RHNhP6OLI5pY6MiFdHa/+DtGkasCAibi2QsRFZHa2xZLPDf6Nx6hEzs67r6+t2CwpzpeDilYKfBnbPZ5TfBThZ0vqltM7MrAwllbXvJlcKLl4puPGGnr+i+zPZm5ktrcKdULtcKbiESsGSNiCrZ7UZ8Jl81mEzs2rwNauO9Gyl4Ih4kuxIcX3gCkmXRcQzjds0Vgr+xlHv5uhp27eKMjMrXfT7PqtO9Gyl4AERMV/SA8CewGVNry2uFPzahSfX/zfHzOqjB04Ddvv6Si9UCp4saaX88erAHsBDHbbPzCydvr72l4rqdmc1naxS8C1kAxcGcy5wpKTbyU4BjqRS8M6S7pM0myUjEX8OHCrpHkl7DrHdULYEfifpXuAm4N8jYlaH7TMzS6fE0YCS9pf0kKQ5kk4eZJtp+ffqA5JuKuMtuFJw8UrB17TIMDOrjpJOA0oaC5wD7AfMA2ZKmhERsxu2mUh2gLF/RDwhae0y9t3tIyszM0stov1laFOBORExN79t50dAc22iDwGXR8QT2a7j2TLegjsrM7Ne18FpQEnHSrqjYTm2IWkS8GTD83n5ukabA6tLulHSnZI+WsZb8NyAZma9roOh640jl1tYZgg10Bw+juy+1H3JJme4TdLt+WWXEXNn1QUzP/dIktwzVtwuSW6qar4AO93370lyr9r680ly91rxxSS5AGNWSHNHQySqu3fCytukCQaun5smd2WlGcL99EtpKhtDdjNqYeWN8psHbNDwfDLQPAnCPOC5iHgFeEXSzWS3HRXqrHwa0Mysx0V/f9vLMGYCUyRtImk8cDgwo2mbnwF7ShqXzz60C9nk5YX4yMrMrNeVNINFRCySdALZVHRjgQsi4gFJx+evnxcRD0q6CriPbHKGb0XE/UX37c7KzKzXlTg3YERcCVzZtO68pudfAb5S2k5xZ2Vm1vs8N6CZmVXeoupOo9Qud1ZmZr2uB0qEjNpoQEl9+VxR90u6NB8l0lX5/FUdVQoeImtVSU9JOruMPDOz0vRH+0tFuax98bL2A/6FbCJbM7NKKXHoete4rH3BsvYAknYC1iGrfrwzZmZVUuEjpna5rH3BsvaSxgBfJauzte8Q73txpeB/XGVHDvrrN3f+4ZmZjYQ7q470aln7vweujIgnW1QeXqxxvq2b131//X9zzKw+KlxUsV0ua7+0kZS1341sapG/ByYA4yW9HBEti5KZmY226IEjq27PDVj7svYR8eGI2DAiNgY+DVzkjsrMKsWjAQubTv3L2puZVVuJZe27xWXtC5a1b9ruu8B329nWzGzUVPiIqV2ewcLMrNe5szIzs6qLvuqe3muXO6suWBhpLhVOTDQ8dcLKC5LkQrqKvvvf/29Jci/Z9p+S5AJMSHW94OE0sfePaXUnRzmO2mmoS9gjd/qsdZPkrhMV/yr1kZWZmVVdLwxdd2dlZtbreqCz6vbQdTMzS62/g2UYkvaX9JCkOZIGvadU0tvyahuHFX8DPrIyM+t5saic66GSxgLnAPsB84CZkmZExOwW232JbH7VUvjIysys15V3ZDUVmBMRcyNiAfAj4OAW230C+AnwbAmtB9xZmZn1vOiPthdJx0q6o2E5tiFqEvBkw/N5+brFJE0CDiUrt1SaUTsNKKmPbCb0ccCDwJER8epo7X+QNk0DFkTErQVzBt4bwBMRcVDBppmZlaeDs4CNFSJaaFVaonn0xteBz0VE31CVKDrVlVnXJV1MNu/e14b7IUnjImJRojZNA14G2u6sBmnPMjPKm5lVRYlD1+cBGzQ8nwzMb9pmZ+BHeUe1JnCgpEURcUWRHbtScAmVgs3MKq28+81nAlMkbUL2HXo4Td+HEbHJwGNJ3wV+UbSjAlcKLlwpOLeipDuARcCZrf7DNFYKPmmVnXjvSpuO4NMzM+tcWeemImKRpBPIvhvHAhdExAOSjs9fL/U6VSNXCl7aSCoFA2wYEfMlvRm4XtKsiHikcYPG88DXrfPB+t+hZ2a1ESXO5BURVwJXNq1r2UlFxFFl7deVgpc2kkrBRMT8/N+5km4EdgAeGWx7M7NRVf95bLs+dL32lYIlrS7pr/LHawJ7ALOH/ikzs9ET/e0vVdXtzmo69a8UvCVwh6R7gRvIrlm5szKzyuiFzsqVggtWCs7v0dpmsNfNzLot+sq736lbPDegmVmPq/IRU7vcWZmZ9bjo95GVjcANK3U6PqQ9my9Mcwny0YUTk+QC7LXii0lyU1X0/cB9/5wkF2DRz9PcovKj05onGCjH+xelmlgGfjNz0vAbjcAWK6T5/8gKSVLL4yMrMzOrvAgfWZmZWcX5yMrMzCqv36MBzcys6jzAwszMKs+dlZmZVV70wNTZozbdkqS+fFqj+yVdmpf96CpJ0yTtXkLOhpKulvSgpNmSNi6heWZmpYh+tb1U1WjODfhaRGwfEVsDC2hv3r2B+lepTAM66qwGac9FwFciYktgKvBs8aaZmZUjQm0vVeVKwQUrBUvaChgXEdcARMTLJXw+Zmal6fNowM71YKXgzYEXJF0ObAJcC5wcEX1N73txpeAD1ngbO66y2cg/RDOzDlT5iKldrhS8tJFUCh4H7ElWcPEJ4MfAUfn7W6yxUvBpG3+oBy53mlldlHktStL+ZAcAY8kODs5sev3DwOfypy8D/yci7i26X1cKXtpIKgXPA+6OiLn5tlcAu9LUWZmZdUtZowEljQXOAfYj++6bKWlGUw2/R4G9I+LPkg4g+yN9l6L77nbxxdpXCgZmAqvn18UA9sGVgs2sQkocDTgVmBMRcyNiAfAj4OCl9hVxa0T8OX96OzC5jPfQ7c5qOjWvFJxfm/o0cJ2kWYCAb3bYPjOzZPr6x7S9SDpW0h0Ny7ENUZOAJxuez8vXDeZo4FdlvAdXCi5YKTh//ZoWOWZmldDJacDG6+sttDr0apku6R1kndXb29/74DyDhZlZj+svbzTgPGCDhueTgWUKpknaFvgWcEBEPF/Gjrt9GtDMzBIr8abgmcAUSZtIGg8cDsxo3CC/7edy4CP52atS+MjKzKzHlTUaMCIWSTqB7B7UscAFEfGApOPz188D/gl4E3BuPpJ6UUTsPFhmu9xZdcHKkeaAdu1EZcYnKN0B+JgV0txyNqE/TbW5VKXnAca9r60ZyDq2zsmnJsl9ZHy6r48NFqb57zdnbJr/j6zQ8lJOdZR4GpCIuBK4smndeQ2PjwGOKW2HOXdWZmY9rq+//ld83FmZmfW4Xpgyx52VmVmPK/M0YLe4szIz63GeyNbMzCovzXCV0eVKwQUrBUt6R/6+BpbXJR1SUhPNzAoL1PZSVa4UXLBScETckL+v7ckmsX2VJWVKzMy6blGo7aWqXCm4YKXgJocBv4qIV0f2sZiZla/KR0ztcqXg4pWCGx0OfG2Q9724UvAha0xl6oQpbX9mZmZF9MI1K1cKXtpIKgWT73s9YBuyDm4ZjTMZn7HREb1w24OZ1YSPrDrTq5WCB3wA+GlELBxmOzOzUdULR1bdnoOjFyoFD/hbstOTZmaV0ofaXqqq253VdGpeKRhA0sZkNV5u6rBdZmbJ9av9papcKbicSsGPMXRpZzOzrumv8BFTuzyDhZlZj+uFEV3urMzMepwHWJiZWeX1S20vw5G0v6SHJM2RdHKL1yXprPz1+yTtWMZ78JFVF5w0ff0kub849anhNxqBfXaclyQXINIUboWH08T+6LT5aYJJV9F3vwe+mCT3P3f8ZJJcgNPGjE+Se+1raf4/8t6V3pwktyx9JeVIGgucA+wHzANmSpoREbMbNjsAmJIvuwD/mf9biI+szMx6XImjAacCcyJibkQsAH4EHNy0zcHARZG5HZiYT5pQiDsrM7Me14/aXoYxCXiy4fk8lh0J3c42HXNnZWbW46KDRdKxku5oWI5tiGrVmzUPNmxnm475mpWZWY/r5GbfxnlMW5hHNgHCgMlA84XcdrbpmI+szMx6XH8HyzBmAlMkbSJpPFmliRlN28wAPpqPCtwVeHFgsvEiRu3ISlIf2Uzo44AHgSO7Xfcpnzx3QUTcWjDny8B7yDr/a4ATI6IX7sMzsx7QV9IEFhGxSNIJZNUlxgIXRMQDko7PXz8PuBI4EJhDVoz2Y2Xsuyuzrku6mGzevZa1nxpJGheRbIDzNOBloO3Oqrk9knYH9mDJtE2/AfamYRooM7NuKvOm4Ii4kqxDalx3XsPjAD5e4i4BVwouo1JwACvm70FktbeeKfbxmJmVpxdmsHCl4IKVgiPiNkk3AE+TdVZnR8SDLd734krB3/jouzh62nYj/xDNzDoQ9Z/H1pWCm3RcKVjSZmQd2uR81TWS9oqImxu3axxh89p3PuvrWWY2anxk1ZlerRR8KHB7RLycb/srYFfg5kG2NzMbVWVNt9RN3R663guVgp8A9pY0TtIKZIMrljkNaGbWLb1QfLHbndV06l8p+DLgEbLTjvcC90bEzztsn5lZMiXeZ9U1rhRcsFJwRPQBxw32uplZt1W5E2qXp1syM+txvTCiy52VmVmPq/K1qHa5szIz63G9MBrQnVUXrHLcxUlyZ2+6TZLcnW9/IUkuwAkrp2nz/WOWuSWuFO9flGrmL3hkfJr/O6aq6Hv5XWclyQX47M5pqiZfOnbNJLk3Luh0gPLo6u+BE4HurMzMepwHWJiZWeXV/7jKnZWZWc/zkZWZmVXeItX/2MqdlZlZj6t/VzWK0y1J6sunNbpf0qV52Y+ukjQtL55YNOdL+fu6X9IyM2CYmXVTL0y3NJpzA74WEdtHxNbAAtqbd2+g/lUq04COOqvm9kh6D7AjWfHHXYDPSFq1pPaZmRXWT7S9FCFpDUnXSHo4/3f1FttsIOkGSQ9KeiCvPTisbk1kewuwmaT3SfqdpLslXStpHQBJ0yWdL+lq4CJJG0u6RdJd+bJ7vt00STdJukTSHyWdKenDkn4vaZakTfPt1pL0E0kz82UPSRuTdZifGpjIttV2rdrT9F62Am6KiEUR8QrZZLb7j8aHaGbWjuhgKehk4LqImAJclz9vtgj4x4jYkqyc0sclbTVcsCsFF6wUTNY5nS7pa8BfkxV8nN3ifS+uFKyxqzFmzMoj+wDNzDo0iqf3DiY7YwVwIdlk4p9r3CAvlvt0/vgvkh4EJtHie7ORKwUvreNKwRFxtaS3AbcC/w3cRvaXQ/N2iysFjxs/qReud5pZTfR1cMzU+Id17vz8+6sd6wx8H0fE05LWHmZfGwM7AL8bLtiVgpc2kkrBRMS/Af+Wb/sD4OHBtjUzG22dHFk1/mHdiqRrgXVbvPT5TtokaQLwE+CkiHhpuO27XXyx9pWCJY2V9Kb88bZk9bGuHvqnzMxGT3Twv2GzIt4ZEVu3WH4GPJOfKSP/99lWGXlV9Z8AF0fE5e28h253VtOpf6XgFYBb8u3PB46IiHSznZqZdWgUh67PYMmBx5G0KK6r7FTVt4EHI+Jr7Qa7UnDxSsGvk40INDOrpFGcdf1M4BJJRwNPAO8HkLQ+2eC3A4E9yM6QzWoYx3BqRFw5VLBnsDAz63Gj1VVFxPPAvi3WzwcOzB//Bui4HKQ7KzOzHreoByZccmdlZtbj2hk4UXXurLrgjvV2SpJ75mvjk+TeuuUaSXIBrp+bJveonYYarzNyv5k5KUkuwAYL09y6edqYNL8Xqar5Anz5ji8myb35rackyd1/7ZaD3iqjynP+tcudlZlZj/ORlZmZVZ6PrMzMrPL6wkdWZmZWcaN4n1Uy7qzMzHpcL1yzKn26pR6vCHyVpBck/aJp/SZ5Xa6HJf1YUprhV2ZmI+BKwa31ZEXg3FfIpglp9iWyOlhTgD8DR3faQDOzVEarUnBKqSey7aWKwETEdWQztS+WT8q4D3BZvupC4JDyP0ozs5Epc9b1bkl2NNODFYEH8ybghYaZ1ueRVb00M6sEjwZsrScrAg+h1YSMy/xmNFbfPG2NbfmbCRt1sAszs5Gr8um9dqXorHq2IvAgngMmShqXH11NBuY3b9RYffOejQ6q/2+OmdVGlQdOtGu0ii/WviLwYCIigBuAw/JVLQuOmZl1Sy9csxqtzmo69a8ITN7+S4F9Jc2T9O78pc8B/yBpDtk1rG932G4zs2R6YTRg6acBe7UicP76noOsnwtMHepnzcy6JXpggMVoHVmZmVmX9BFtL0VIWkPSNfkECddIWn2IbcfmtzP9YrBtGrmzMjPrcaN4GvBk4Lp8goTr8ueDORF4sN1gd1ZmZj0uItpeCjqYbGIEGGKCBEmTgfcA32o32BPZdsFv+ldNkrva2EXDbzQCDz28ZpJcgJWVZlDt6bPWTZK7xQrp/r6bk+i/37WvPTX8RiNw6dh0vxepKvru9cAZSXJfn37C8Bt1USdHTI33hObOz2+9acc6A/fDRsTTktYeZLuvk00O0eo+2JbcWZmZ9bhOhqQ33hPaiqRrgVZ/DX6+nXxJ7wWejYg78/tu2+LOysysx5U53VJEvHOw1yQ9I2m9/KhqPeDZFpvtARwk6UBgRbIZhL4fEUcMtV9fszIz63GjOMBiBksmfmg5QUJEnBIRkyNiY+Bw4PrhOipwZ2Vm1vNGsbM6E9hP0sPAfvlzJK0v6coiwT4NaGbW40brpuCIeB7Yt8X6+cCBLdbfSMOED0NxpeDOcgarFHyCpDmSQlK6IVJmZiPQC9MtuVLwIDqsFPxbsrIjj3fcMjOzxHphItvUpwFvAbaV9D7gNLJaVs8DH46IZyRNB9YHNgaek3Qq8D1g5fznT4iIW/PhjV8gKx+yPXA5WR2rE4GVgEMi4hFJawHnARvmP38S2WzvxwN9ko4gK9T4h+btIuK3ze0BPtT4ZiLiulZDLSPibmhZisTMrOv6ov5FQlwpuHilYDOzSuuFiWxdKXjZ7TqtFNyWxrvCD584lT0mTCl7F2ZmLVX5WlS7XCl42e06raHVlsa7ws/e4Ij6/+aYWW1U+VpUu1wpmGKVgs3Mqq4/ou2lqlwpuIRKwZI+KWkeMBm4T1LbMwmbmaXm0YAtLKeVgs8CzhrqZ83MusWjAc3MrPKqfHqvXe6szMx6XJVP77XLnZWZWY/zkZWNyHYLXx9+oxH4abyUJPf41TsdlNm+p19aI0nuOpHmV3uFJKkD2WlmQHnvSm9OknvjgnS/F/uv3aoMUnGpKvquOP3sJLll8ZGVmZlVXl/0dbsJhbmzMjPrcZ5uyczMKs/TLZmZWeX1wpGVy9qbmfW40ZpuSdIakq6R9HD+7+qDbDdR0mWS/iDpQUm7DZftzsrMrMeN4nRLJwPXRcQU4Lr8eSv/AVwVEW8hm7j8weGC2+qsJH1e0gP5XHr3SNpF0rckbdXmG2ibpJeHeG2MpLMk3S9plqSZkjbJXzu17LYM0obtJR3Y8Hy6pE+Pxr7NzEaiL/rbXgo6GLgwf3whcEjzBpJWBfYiKx9FRCyIiBeGCx72mlV+ePZeYMeIeEPSmsD4iDim3daX6INklXy3jYh+SZNZMtntqcAXm39AWd0P5TO5l2F7soKQV5aUZ2aWVCfXrBpr7+XOz0sctWOdgbqDEfG0pLVbbPNm4L+B70jaDrgTODEihpy4vJ0jq/WA5yLijbwBz0XEfEk3StoZQNLRkv6Yr/umpLPz9d/Nj4RulTRX0mH5+gmSrpN0V36EdHCbH8R6LCkhQkTMi4g/SzqTvOijpIslbZyfBz0XuAvYQNJn8iOx+yR9IW/HwHbfzI8cr5a0Uv7a2/Jtb5P0lfxobjzwz8AH830NTIa7Vf7e50r6ZJvvxcxsVHRyzSoizo+InRuWpToqSdfm34fNS7vf4+OAHYH/jIgdyA44BjtduFg7ndXVZF/2f5R0rqS9mxq+PvB/gV2B/YC3NP38esDbyY7OzszXvQ4cGhE7klX5/apaVEhs4RLgfXlH8VVJOwBExMnkRR8j4sP5tlsAF+UfxhbAFGAq2ZHRTpL2yrebApwTEW8FXgD+Jl//HeD4iNiNrGoxEbEA+Cfgx/m+fpxv+xbg3Xn+6ZKWmehA0rGS7pB0x4xX57bxVs3MyhFZJ9TW0kbWOyNi6xbLz4BnlFWEJ/+31VQk84B5EfG7/PllZJ3XkIbtrCLiZWAnssPC/yYrT39UwyZTgZsi4n8iYiFZvadGV0REf0TMBtbJ1wn4oqT7gGuBSQ2vDdWWeWQdzylkFYKvk7TvIJs/HhG354/flS93kx1pvYWskwJ4NCLuyR/fCWwsaSKwSkTcmq//wTBN+2VEvJGXKHm21Xtp/GvloL9OM/2NmVkr/UTbS0EzWFJg90hal4b6E/CkpC3yVfsCs4cLbus+q4joI6sZdaOkWSxd7Xe4I6LGcvQD234YWAvYKSIWSnoMWLHNtrwB/Ar4laRnyC7gXddi08bznwLOiIj/atxA0sZN7esDVmL499SsOcP3r5lZZYzifVZnApdIOhp4Ang/LD4D962IGBic9gng4vzSylzgY8MFD3tkJWkLSVMaVm0PPN7w/PfA3pJWlzSOJafRhrIa8GzeUb0D2KiNn0HSjvmbRtIYsoKKA21Z2Or0W+7XwN9JmpD/7KRBLvwBEBF/Bv4iadd81eENL/8FWKWd9pqZVcFojQaMiOcjYt+ImJL/+z/5+vkNHRURcU9+pmnbiDgk/84dUjvXrCYAF0qanZ+224qsTP3ATp8iG4X3O7JTerOBF4fJvJisrPwdZEdZf2ijHQBrAz+XdD9wH7AIGJju+HyykvIXN/9QRFxNdirvtvzI8DKG73COBs6XdBvZkdbAe7qBbEBF4wALM7PKGq2bglNSGYeHkiZExMv5kdVPgQsi4qeFg7to4D3lj08G1ouIE8vIvmXdw5L8Rkwfl6ZEyLkT0pWCuCtRiZA5iWp5rNWfpowHwJyxaWbGTvVfb6O+hCVCJqYpEbLW3mnO0KcsEbLCmm8u/Eu34oobtv2d8/rrT6T7JS+grP9y0yW9k+y609XAFSXldtN7JJ1C9hk9DhzV3eaYmY2M61nlIqLUGRwkbQN8r2n1GxGxS5n7GUo+LP3Hw25oZlZxvTCRbSVHrUXELLKBHGZmVlCVr0W1rZObxbyM/gIcW7fsuuXWsc3+LPxZLG+LZ12vvmOH36Ry2XXLTZldt9yU2XXLTZmdss09yZ2VmZlVnjsrMzOrPHdW1dfu1PxVyq5bbsrsuuWmzK5bbsrslG3uSaXcFGxmZpaSj6zMzKzy3FmZmVnlubMyM7PKc2dVA5L2KyFjVUmbtli/bcHcdSWtmz9eS9L/kvTWIpmD7OeLZWfmuZvkbW6ucN1pzoaSVswfS9LHJH1D0v/JJ3geae5BA7kpSNproAiepLdL+rSk95SQO0HSYZI+JekTkvbPy/oUyRwn6ThJV0m6T9K9kn4l6fghygMVJsmDISrAAyxqQNITEbFhgZ//APB1sirGKwBHRcTM/LW7ImLYktKD5B4HnExWQuVLZJP9PgDsAXw5Ir49wtyzmlcBHwEuAoiIT44kN8++IiIOyR8fTPa53AjsTlag87sjzL0fmBoRr0r6ErAp2YTO++Rt/rsR5r5GVkj0V8APgV9HVgy1MElfJ6v0PY6s5tu++X72Bu6OiM+MMPcDwGeAe4F3ALeS/WG8DfDhyKZTG0nuD4EXgAvJSqMDTCYrBrtGRIy4ZI+kwab/F3BvREweaXbTfsaSVRJf/AdMRDxRRnavc2dVEZJmDPYSsE9ErFwg+x7ggIh4WtJUsi/9UyPickl3R8QOI8ydBexCVl35cWCziPiTpNWBGyJi+xHmziPrQK5mSdXmfwc+DRARF44kN89e/H4l3Ur25fmopDWB6yJiuxHmzo6IrfLHdwJvi8gq2Um6t0Du3WQd3mFkRUC3JivD88OIuGkkmQ3ZD+R5KwFPAZPyznYFss5q6xHm3gfsmmetCVwcEe/Oj+LPi4jdR5j7UERsMchrf4yIzUeSm/98H9nvcGN5jMifT4qI8SPNbtjHJ4DTgWeAgSqHERGFzm4sLyo5ke1yak/gCODlpvUi++u3iLER8TRARPw+r878C0mToVDtgIUR8SrwqqRHIuJP+T7+LKlI7pbAvwD7A5+JiKcknV6kk2rQ2K5xEfEoQEQ8J6lImdQnJe0TEdcDjwEbAI9LelOBzLxp8Wfgm8A381OuHwDOlDQ5IjYomB0N73vgs+mn2CUCAa/lj18hK5pKRNwnadUCuX+W9H7gJw1/CIwhK50+bKXZYcwF9m11lCPpyYLZA04EtoiI50vKW664s6qO24FXW/21LOmhgtl/kbRpRDwCkB9hTSM7TVXk+lK/pBUiYiGw+DpHfo1lxF92EfEX4CRJOwHfl/TLInlNtpP0EtkX6l9JWjc/GhxPsTqFxwAXSZpOVlX6nvyoaHXgHwrkLlUIL/+D4CzgLEkbFcgF+KWkW8jq0H0LuETS7WSnAW8ukHslcJWkm4ADgEth8am2IoX9Dic73XyupIHOaSJZ9e7DC+RCdjp4daDVKbkvF8we8CTDV1G3Qfg04HJA0nbAKxExp2n9CsAHIuLiEeZuCMyPiEVN6ycBW0bEtSNtc0OWgL8HdouII4rmDbGfiWRtvq1gzpbA5mR/CM4DZg4cBYwwb1pE3FikTcPk70Z2hHW7sgE4h5J9YV9WsN0HAluRXe+5Jl83BlghIt4ood1vIvv+eq5oVmqSBv5YeSuwBfBLYPFnEBFf60a76sadlZnVnqT9BjrFqmVLOn2IlyMi/nmk2csTd1ZmVntFR8yORrak90fEpcOts9bcWZlZLSQeMZssu2Efy9wmUuTWkeWNB1hUSH4PxoUprs2kyq5bbsrsuuWmzE6Um3LEbLJsSQcABwKTmu4hXBVY1PqnrJk7qwqJiD5ls0CMj4gFdciuW27K7LrlpsxOlJtyxGzK7PnAHcBBwJ0N6/8CfKpg9nLDnVX1PAb8Nj8t8crAypJGDKXKrltuyuy65abMLjU3Ig4Y4rW9RpI5Stn3AvdK+kF+m4eNgDur6pmfL2OAVWqSXbfclNl1y02ZnbLNdXRXi5vlXyQ76vpX3yw8NA+wqChJK0fEK8NvWZ3suuWmzK5bbsrslG2uE0lfBvqAH+SrDie7JvYi8PaIeF+32lYHnnW9YiTtJmk28GD+fDtJ51Y5u265KbPrlpsyO2Wba2qPiDglImbly+eBvSPiS8DGXW5b5bmzqp6vA+8GnofF57sLnTMfhey65abMrltuyuzScyWNlfT94k0b3ezcBEm7NOxvKjAhf+pRgcPwNasKiogns1mGFiulJETK7LrlpsyuW27K7LJz6zgyssExwAWSJpCd/nsJOEbSysAZCfbXU9xZVc+TknYHQtnkqp8kP41S4ey65abMrltuyuxUuY9Rv5GRRFZDbhtJq5GNF3ih4eVLiub3OndW1XM88B/AJLKJUK8mm8i1ytl1y02ZXbfclNmpcus4MhJJfwX8Ddn1qXEDR5yeG7A9Hg1YMZL2iIjfDreuStl1y02ZXbfclNkp25xn1WpkpKSryEb+3UnD6dCI+GqZ++lZEeGlQgtwVzvrqpRdt9w6ttmfxVIZuwGzgSfy59sB55b0WaTMvr+MnOV18WnAilBWV2h3YC0tqX8D2fxhRYoCJsuuW27K7LrlpsxO2ebc18lGGc6AbJShpLJHRqbIvlXSNhExq6S85Yo7q+oYTzaMdRxLnyt/CTisotl1y02ZXbfclNkp2wzUc2Qk8HbgKEmPkhVfVLa72Lak/J7ma1YVI2mjiHg80TnzJNl1y02ZXbfclNkJcy8DvgacDexKNspw54goWto+dfZGrdZHxONFs5cHvim4etZPeNd/quy65abMrltuyuxUuccDH2fJKMPtKXdkZJLsvFPagKw+1uPAq/g7uH3dvmjmZekF+B3ZL/TdDetKuTCbKrtuuXVssz+LpXL3aGddBbNPB34O/DF/vj7w2zKyl4fFvXoFRcSTTatKPR+fIrtuuSmz65abMjtR7jfaXFe17EPJalq9AhAR8/Fs9G3zAIvq8UwF6XNTZtctN2V2qbl1HBnZZEFEhPIyIcqmWbI2+ciqelqdM/94xbPrlpsyu265KbPLzm0eZTiwpBgZWWb2gEsk/RcwUdL/Bq4FvllSds/zaEAzq5WajowUMBl4C/AusmHrv46Ia8raR6/zacCKkbQJ8Any+cMG1kfEQVXNrltuyuy65abMTtjm9SX9iuxIaENJ2wHHRUQZo/aSZOen/66IiJ0Ad1Aj4M6qeq4Avk02aqi/Jtl1y02ZXbfclNmpcr9OPWewuF3S2yKbfd065M6qel6PiLNqll233JTZdctNmZ2szVHPGSzeARwn6XGyEYGewaIDvmZVMZI+BEwhK6fwxsD6iLirqtl1y02ZXbfclNkJcz2DxXLIR1bVsw3wEWAflpw6ifx5VbPrlpsyu265KbNT5baqk1XmyMhU2f8aER9pXCHpe2SfkQ3DR1YVI+kPwLaRoKx2quy65abMrltuyuyUba4jSXdFxI4Nz8cCsyJiqy42qzZ8ZFU99wITgWdrlF233JTZdctNmZ0kt24jIyWdApwKrCTpJbJrVQALgPNH3NjljDur6lkH+IOkmSx9nr/w/xETZtctN2V23XJTZqfKvYIajYyMiDOAMySdERGnlJG5PPJpwIqRtHer9RFxU1Wz65abMrtuuSmzE+b+LiJ2KZIxmtn5wIoXIuLF/Pk7gEOAx4BzfJq0Pe6szKxW6jYyUtLvgEMjYr6k7cmmWToD2BZYGBHHFGr0csKnAStG0q5kszxvSTZf2VjglYhYtarZdctNmV233JTZCdtct5GRK+UzrAMcAVwQEV+VNAa4p0DucsWdVfWcDRwOXArsDHyU7C+9KmfXLTdldt1yU2anyj0UeHOi02cpshvvMN4HOAUgIvqbbj62IbizqqCImCNpbET0Ad+RdGvVs+uWmzK7brkpsxPl1m1k5PWSLgGeBlYHrgeQtB7ZiEBrgzur6nk1r/1zj6Qvk/2Cl1X3JlV23XJTZtctN2V2qty6jYw8CfggsB7w9ohYmK9fF/h8gdzligdYVEw+cugZsnP8nwJWA86NiDlVza5bbsrsuuWmzE6YW7uRkW3u+7aI2C31furKnVWF5He0XxgRR9Qlu265KbPrlpsyO2Wbe5WkuyNih263o6pcKbhC8vP6a+WnTmqRXbfclNl1y02ZnbLNknaVNFPSy5IWSOrLZ4aodHYbfOQwBF+zqp7HgN9KmkFWRgCAiPhahbPrlpsyu265KbNT5dZxZKQV5M6qeubnyxhglZpk1y03ZXbdclNmJ2tzHUdGtsHj2Ifga1ZmViuSbgbeCXwL+BPZKMOjImK7Kme3se+tI+L+1PupK3dWFSNpLeCzwFuBFQfWR0Thu/NTZdctN2V23XJTZifMrdXISEl/ofX1qIFKwYVnIVkeeIBF9VwM/AHYBPgC2Xn/mRXPrltuyuy65abMLj03H2X4bxHxekS8FBFfiIh/KKmjSpIdEatExKotllXcUXUgIrxUaAHuzP+9r2HdTVXOrltuHdvsz2Kp3F8D48t476OZ3bCPtYENB5aU++qlxQMsqmfg7vanJb2H7AL15Ipn1y03ZXbdclNmp8p9jPqNjETSQcBXgfXJpnPaCHiQ7DSpDcOdVfX8q6TVgH8km7F6VbJz51XOrltuyuy65abMTpVbx5GRAP8C7ApcGxE7KKtr9bcl76NneYBFRUhaETge2AyYBXw7IhZVObtuuSmz65abMjtlm+tM0h0RsbOke4EdIpt1/fcRMbXbbasDH1lVx4Vkp01uAQ4AtgJOrHh23XJTZtctN2V2yjbXcmRk7gVJE4CbgYslPQss951427p90cxLtgCzGh6PA+6qenbdcuvYZn8WLfOvBo4mu96zN3AB8KUaZK9MVoByHHAk8EngTWV+Nr28eOh6dQxcjCbKP2WSKrtuuSmz65abMjtlmyH7gv82WUn4myLi78iuBVU6OyJeiYi+iFgUERdGxFkR8XwZ2csDnwasju0aJswUsFL+vIwbB1Nl1y23jm32Z7GsOo6MRNL/Ar5ENnRd+KbgjniAhZnViqT3kl0P24Alowy/EBEzKp49B3hfRDxYNGt55M7KzGqhjiMjm/bx24jYo8zM5Yk7KzOrBUk/ZulRho9HRCmjDFNmN+zjP8hK2V8BvDGwPiIuL3M/vcqdlZnVgqRZEbFN/ngc8PuI2LHq2Q37+E6L1ZEP4rBheICFmdXFUqMMpVLLP6XMHsj9WOmhyxEfWZlZLUjqY8l8fQJWAl6lhFF1KbMb9nFWi9UvAndExM+K5vc6d1ZmZqNA0vnAW4BL81V/AzxANvJwbkSc1KWm1YI7KzOzUSDpeuBdA6MM82tjVwP7kc36sVU321d1nsHCzGx0TCKbcmnAysD6EdFHw+hAa80DLMzMRseXgXsk3Uh2LWwv4IuSVgau7WbD6sCnAc3MRomk9YCpZJ3V7yNifpebVBvurMzMEpL0loj4g6SW921FxF2j3aY6cmdlZpaQpPMj4lhJN+SrlvrSjXJqZfU8d1ZmZglJmgo8ERF/yp8fSTZs/TFgekT8TxebVxseDWhmltZ5wAIASXsBZ5BVU34ROL+L7aoVjwY0M0trbMPR0weB8yPiJ8BPJN3TvWbVi4+szMzSGpvfAAywL3B9w2s+YGiTPygzs7R+CNwk6TngNbIyJEjajOxUoLXBAyzMzBKTtCuwHnB1RLySr9scmOCh6+1xZ2VmZpXna1ZmZlZ57qzMzKzy3FmZmVnlubMyM7PK+/9g/2efCVn6SQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Heat Map\n",
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adverse-justice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dividing dataframe into target and individual variables.\n",
    "X = db.drop(\"Signal_Strength\", axis = 1)\n",
    "Y = db[\"Signal_Strength\"]\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "judicial-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07625309 0.09801904 0.08156758 0.07960914 0.07618677 0.07496102\n",
      " 0.10116914 0.08463761 0.07424112 0.10075833 0.15259716]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "\n",
    "#feature_importances is an inbuilt class for tree based classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-dispute",
   "metadata": {},
   "source": [
    " Parameter 11 is the most effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acute-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing\n",
    "X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "asian-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling training and testing data\n",
    "X_Train_S = StandardScaler().fit_transform(X_Train)   \n",
    "\n",
    "X_Test_S = StandardScaler().fit_transform(X_Test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-pearl",
   "metadata": {},
   "source": [
    "-- Forward Propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "official-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LeakyReLU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "related-movement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1536      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 12,417\n",
      "Trainable params: 12,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model_Regressor = Sequential()\n",
    "\n",
    "#The Input layer. \n",
    "NN_model_Regressor.add(Dense(128, kernel_initializer='normal',input_dim = X_Train.shape[1], activation='relu'))\n",
    "\n",
    "#The Hidden layers. \n",
    "NN_model_Regressor.add(Dense(64, kernel_initializer='normal',activation='relu')) \n",
    "\n",
    "NN_model_Regressor.add(Dense(32, kernel_initializer='normal'))\n",
    "NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "NN_model_Regressor.add(Dense(16, kernel_initializer='normal'))\n",
    "NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "#The Output layer. \n",
    "NN_model_Regressor.add(Dense(1, kernel_initializer='normal'))  # except softmax\n",
    "NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "#Compiling Network.\n",
    "NN_model_Regressor.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "NN_model_Regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "juvenile-attention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.6601 - accuracy: 0.0000e+00 - val_loss: 5.5602 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5.6473 - accuracy: 0.0000e+00 - val_loss: 5.5422 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5.6231 - accuracy: 0.0000e+00 - val_loss: 5.5039 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5.5683 - accuracy: 0.0000e+00 - val_loss: 5.4131 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5.4365 - accuracy: 0.0000e+00 - val_loss: 5.1955 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5.1261 - accuracy: 0.0000e+00 - val_loss: 4.6966 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.4383 - accuracy: 0.0000e+00 - val_loss: 3.6192 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 3.0479 - accuracy: 0.0000e+00 - val_loss: 1.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7418 - accuracy: 0.0000e+00 - val_loss: 1.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.7947 - accuracy: 0.0000e+00 - val_loss: 1.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3857 - accuracy: 0.0000e+00 - val_loss: 1.3266 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3203 - accuracy: 0.0000e+00 - val_loss: 1.1504 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.1361 - accuracy: 0.0000e+00 - val_loss: 1.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1195 - accuracy: 0.0000e+00 - val_loss: 1.0376 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0417 - accuracy: 0.0000e+00 - val_loss: 0.9911 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0061 - accuracy: 0.0000e+00 - val_loss: 0.9596 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9668 - accuracy: 0.0000e+00 - val_loss: 0.9338 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9310 - accuracy: 0.0000e+00 - val_loss: 0.8924 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9017 - accuracy: 0.0000e+00 - val_loss: 0.8669 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.8737 - accuracy: 0.0000e+00 - val_loss: 0.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.8484 - accuracy: 0.0000e+00 - val_loss: 0.8170 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.8219 - accuracy: 0.0000e+00 - val_loss: 0.8000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7957 - accuracy: 0.0000e+00 - val_loss: 0.7723 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7802 - accuracy: 0.0000e+00 - val_loss: 0.7605 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7557 - accuracy: 0.0000e+00 - val_loss: 0.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7349 - accuracy: 0.0000e+00 - val_loss: 0.7197 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7192 - accuracy: 0.0000e+00 - val_loss: 0.6955 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7033 - accuracy: 0.0000e+00 - val_loss: 0.6815 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6863 - accuracy: 0.0000e+00 - val_loss: 0.6638 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.0000e+00 - val_loss: 0.6584 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.0000e+00 - val_loss: 0.6357 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.0000e+00 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.0000e+00 - val_loss: 0.6119 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.0000e+00 - val_loss: 0.6059 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.0000e+00 - val_loss: 0.5915 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.0000e+00 - val_loss: 0.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.0000e+00 - val_loss: 0.5745 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5844 - accuracy: 0.0000e+00 - val_loss: 0.5684 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5792 - accuracy: 0.0000e+00 - val_loss: 0.5715 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5750 - accuracy: 0.0000e+00 - val_loss: 0.5591 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.0000e+00 - val_loss: 0.5586 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.0000e+00 - val_loss: 0.5479 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.0000e+00 - val_loss: 0.5393 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5520 - accuracy: 0.0000e+00 - val_loss: 0.5444 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.0000e+00 - val_loss: 0.5394 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.0000e+00 - val_loss: 0.5341 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.0000e+00 - val_loss: 0.5290 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/350\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5333 - accuracy: 0.0000e+00 - val_loss: 0.5383 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.0000e+00 - val_loss: 0.5309 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/350\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.0000e+00 - val_loss: 0.5157 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.0000e+00 - val_loss: 0.5329 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.0000e+00 - val_loss: 0.5282 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.0000e+00 - val_loss: 0.5137 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.0000e+00 - val_loss: 0.5171 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5182 - accuracy: 0.0000e+00 - val_loss: 0.5185 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.0000e+00 - val_loss: 0.5090 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/350\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5117 - accuracy: 0.0000e+00 - val_loss: 0.5195 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.0000e+00 - val_loss: 0.5206 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5079 - accuracy: 0.0000e+00 - val_loss: 0.5092 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5121 - accuracy: 0.0000e+00 - val_loss: 0.5111 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.0000e+00 - val_loss: 0.5370 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.0000e+00 - val_loss: 0.5088 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.0000e+00 - val_loss: 0.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.0000e+00 - val_loss: 0.5130 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.0000e+00 - val_loss: 0.5112 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.0000e+00 - val_loss: 0.5036 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.0000e+00 - val_loss: 0.5040 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.0000e+00 - val_loss: 0.5158 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.0000e+00 - val_loss: 0.5042 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.0000e+00 - val_loss: 0.4938 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.0000e+00 - val_loss: 0.5030 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.0000e+00 - val_loss: 0.5134 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.0000e+00 - val_loss: 0.4959 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.0000e+00 - val_loss: 0.5153 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.0000e+00 - val_loss: 0.4974 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.0000e+00 - val_loss: 0.4914 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.0000e+00 - val_loss: 0.5265 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.0000e+00 - val_loss: 0.5012 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.0000e+00 - val_loss: 0.4925 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.0000e+00 - val_loss: 0.5037 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.0000e+00 - val_loss: 0.5012 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.0000e+00 - val_loss: 0.4939 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.0000e+00 - val_loss: 0.4958 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.0000e+00 - val_loss: 0.5024 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.0000e+00 - val_loss: 0.4984 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/350\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4892 - accuracy: 0.0000e+00 - val_loss: 0.5064 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.0000e+00 - val_loss: 0.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.0000e+00 - val_loss: 0.5061 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.0000e+00 - val_loss: 0.5049 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.0000e+00 - val_loss: 0.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.0000e+00 - val_loss: 0.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.0000e+00 - val_loss: 0.5161 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.0000e+00 - val_loss: 0.4917 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.0000e+00 - val_loss: 0.4944 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.0000e+00 - val_loss: 0.5029 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.0000e+00 - val_loss: 0.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.0000e+00 - val_loss: 0.4881 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.0000e+00 - val_loss: 0.5011 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.0000e+00 - val_loss: 0.4910 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.0000e+00 - val_loss: 0.4920 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.0000e+00 - val_loss: 0.5136 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.0000e+00 - val_loss: 0.4973 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.0000e+00 - val_loss: 0.4843 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.0000e+00 - val_loss: 0.5051 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.0000e+00 - val_loss: 0.4881 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.0000e+00 - val_loss: 0.4911 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.0000e+00 - val_loss: 0.4900 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.0000e+00 - val_loss: 0.5026 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.0000e+00 - val_loss: 0.4991 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.0000e+00 - val_loss: 0.4826 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.0000e+00 - val_loss: 0.4917 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.0000e+00 - val_loss: 0.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.0000e+00 - val_loss: 0.4843 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.0000e+ - 0s 4ms/step - loss: 0.4760 - accuracy: 0.0000e+00 - val_loss: 0.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.0000e+00 - val_loss: 0.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.0000e+00 - val_loss: 0.5043 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.0000e+00 - val_loss: 0.5028 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.0000e+00 - val_loss: 0.4840 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.0000e+00 - val_loss: 0.4916 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/350\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4760 - accuracy: 0.0000e+00 - val_loss: 0.4825 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.0000e+00 - val_loss: 0.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.0000e+00 - val_loss: 0.4766 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.0000e+00 - val_loss: 0.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.0000e+00 - val_loss: 0.5100 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.0000e+00 - val_loss: 0.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.0000e+00 - val_loss: 0.4782 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.0000e+00 - val_loss: 0.4842 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.0000e+00 - val_loss: 0.4959 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.0000e+00 - val_loss: 0.4890 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.0000e+00 - val_loss: 0.4777 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.0000e+00 - val_loss: 0.4831 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.0000e+00 - val_loss: 0.4892 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.0000e+00 - val_loss: 0.4926 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.0000e+00 - val_loss: 0.4899 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.0000e+00 - val_loss: 0.4916 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.0000e+00 - val_loss: 0.4915 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.0000e+00 - val_loss: 0.4866 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.0000e+00 - val_loss: 0.5020 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.0000e+00 - val_loss: 0.4811 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.0000e+00 - val_loss: 0.4828 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.0000e+00 - val_loss: 0.4845 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.0000e+00 - val_loss: 0.4937 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.0000e+00 - val_loss: 0.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.0000e+00 - val_loss: 0.4799 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.0000e+00 - val_loss: 0.4830 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.0000e+00 - val_loss: 0.4977 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.0000e+00 - val_loss: 0.5272 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.0000e+00 - val_loss: 0.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.0000e+00 - val_loss: 0.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.0000e+00 - val_loss: 0.4807 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.0000e+00 - val_loss: 0.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.0000e+00 - val_loss: 0.5005 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.0000e+00 - val_loss: 0.5038 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.0000e+00 - val_loss: 0.4753 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.0000e+00 - val_loss: 0.5028 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.0000e+00 - val_loss: 0.5035 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.0000e+00 - val_loss: 0.4894 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.0000e+00 - val_loss: 0.4768 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.0000e+00 - val_loss: 0.4788 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.0000e+00 - val_loss: 0.4964 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.0000e+ - 0s 5ms/step - loss: 0.4534 - accuracy: 0.0000e+00 - val_loss: 0.4825 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.0000e+00 - val_loss: 0.4862 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.0000e+00 - val_loss: 0.5095 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.0000e+00 - val_loss: 0.4886 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.0000e+00 - val_loss: 0.4812 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.0000e+00 - val_loss: 0.4797 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.0000e+00 - val_loss: 0.4946 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.0000e+00 - val_loss: 0.4983 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.0000e+00 - val_loss: 0.4828 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.0000e+00 - val_loss: 0.4828 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.0000e+00 - val_loss: 0.4808 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.0000e+00 - val_loss: 0.4806 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.0000e+00 - val_loss: 0.4776 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.0000e+00 - val_loss: 0.4901 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.0000e+00 - val_loss: 0.4817 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.0000e+00 - val_loss: 0.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.0000e+00 - val_loss: 0.5005 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.0000e+00 - val_loss: 0.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.0000e+00 - val_loss: 0.4817 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.0000e+00 - val_loss: 0.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.0000e+ - 0s 4ms/step - loss: 0.4520 - accuracy: 0.0000e+00 - val_loss: 0.4789 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.0000e+00 - val_loss: 0.4799 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.0000e+00 - val_loss: 0.4800 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.0000e+00 - val_loss: 0.4943 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.0000e+00 - val_loss: 0.5048 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.0000e+00 - val_loss: 0.4945 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.0000e+00 - val_loss: 0.4895 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.0000e+00 - val_loss: 0.4994 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.0000e+00 - val_loss: 0.4926 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.0000e+00 - val_loss: 0.4765 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.0000e+00 - val_loss: 0.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.0000e+00 - val_loss: 0.5074 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.0000e+00 - val_loss: 0.5023 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.0000e+00 - val_loss: 0.4829 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.0000e+00 - val_loss: 0.4761 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.0000e+00 - val_loss: 0.4809 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.0000e+00 - val_loss: 0.5155 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.0000e+00 - val_loss: 0.5007 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.0000e+00 - val_loss: 0.4767 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.0000e+00 - val_loss: 0.4815 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.0000e+00 - val_loss: 0.4943 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.0000e+00 - val_loss: 0.4909 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.0000e+00 - val_loss: 0.4847 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/350\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.0000e+00 - val_loss: 0.4924 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.0000e+00 - val_loss: 0.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.0000e+00 - val_loss: 0.4796 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.0000e+00 - val_loss: 0.4704 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.0000e+00 - val_loss: 0.4701 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.0000e+00 - val_loss: 0.5199 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.0000e+ - 0s 4ms/step - loss: 0.4525 - accuracy: 0.0000e+00 - val_loss: 0.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.0000e+00 - val_loss: 0.4684 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.0000e+00 - val_loss: 0.4730 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.0000e+00 - val_loss: 0.4875 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.0000e+00 - val_loss: 0.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.0000e+00 - val_loss: 0.4836 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.0000e+00 - val_loss: 0.4753 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.0000e+00 - val_loss: 0.4739 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.0000e+00 - val_loss: 0.4791 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.0000e+00 - val_loss: 0.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.0000e+00 - val_loss: 0.4712 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.0000e+00 - val_loss: 0.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.0000e+00 - val_loss: 0.4975 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.0000e+00 - val_loss: 0.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.0000e+00 - val_loss: 0.4792 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.0000e+00 - val_loss: 0.4863 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.0000e+00 - val_loss: 0.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.0000e+00 - val_loss: 0.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.0000e+00 - val_loss: 0.4926 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.0000e+00 - val_loss: 0.5240 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.0000e+00 - val_loss: 0.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.0000e+00 - val_loss: 0.4699 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.0000e+00 - val_loss: 0.5682 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.0000e+00 - val_loss: 0.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.0000e+00 - val_loss: 0.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - val_loss: 0.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.0000e+00 - val_loss: 0.4994 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.0000e+00 - val_loss: 0.4985 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.0000e+00 - val_loss: 0.5076 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.0000e+00 - val_loss: 0.4877 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.0000e+00 - val_loss: 0.4789 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.0000e+00 - val_loss: 0.4851 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.0000e+00 - val_loss: 0.5071 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.0000e+00 - val_loss: 0.4867 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.0000e+00 - val_loss: 0.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.0000e+00 - val_loss: 0.4830 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.0000e+00 - val_loss: 0.4956 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.0000e+00 - val_loss: 0.4835 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.0000e+00 - val_loss: 0.4908 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.0000e+00 - val_loss: 0.5020 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.0000e+00 - val_loss: 0.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.0000e+00 - val_loss: 0.4722 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.0000e+00 - val_loss: 0.4799 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.0000e+00 - val_loss: 0.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.0000e+ - 0s 4ms/step - loss: 0.4253 - accuracy: 0.0000e+00 - val_loss: 0.4729 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.0000e+00 - val_loss: 0.4758 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.0000e+00 - val_loss: 0.4786 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.0000e+00 - val_loss: 0.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.0000e+00 - val_loss: 0.4913 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.0000e+00 - val_loss: 0.4778 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.0000e+00 - val_loss: 0.4774 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.0000e+00 - val_loss: 0.4710 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.0000e+ - 0s 4ms/step - loss: 0.4265 - accuracy: 0.0000e+00 - val_loss: 0.4743 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.0000e+00 - val_loss: 0.4781 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.0000e+00 - val_loss: 0.4980 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.0000e+00 - val_loss: 0.5025 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.0000e+00 - val_loss: 0.4793 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.0000e+00 - val_loss: 0.4753 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.0000e+00 - val_loss: 0.4696 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.0000e+00 - val_loss: 0.4905 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.0000e+00 - val_loss: 0.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/350\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.0000e+ - 0s 5ms/step - loss: 0.4299 - accuracy: 0.0000e+00 - val_loss: 0.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.0000e+00 - val_loss: 0.4927 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.0000e+00 - val_loss: 0.4873 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.0000e+00 - val_loss: 0.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.0000e+00 - val_loss: 0.4825 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.0000e+00 - val_loss: 0.4877 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.0000e+00 - val_loss: 0.4859 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.0000e+00 - val_loss: 0.4780 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.0000e+00 - val_loss: 0.4857 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.0000e+00 - val_loss: 0.4825 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.0000e+00 - val_loss: 0.4954 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.0000e+00 - val_loss: 0.5038 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.0000e+00 - val_loss: 0.4828 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.0000e+00 - val_loss: 0.5109 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.0000e+00 - val_loss: 0.4790 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.0000e+00 - val_loss: 0.4749 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.0000e+00 - val_loss: 0.4919 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.0000e+00 - val_loss: 0.4988 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.0000e+00 - val_loss: 0.4954 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.0000e+00 - val_loss: 0.4984 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.0000e+00 - val_loss: 0.4919 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.0000e+00 - val_loss: 0.4751 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.0000e+00 - val_loss: 0.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.0000e+00 - val_loss: 0.5352 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.0000e+00 - val_loss: 0.5192 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.0000e+00 - val_loss: 0.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.0000e+00 - val_loss: 0.4745 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.0000e+00 - val_loss: 0.4762 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.0000e+00 - val_loss: 0.4897 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.0000e+00 - val_loss: 0.5061 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.0000e+00 - val_loss: 0.4794 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.0000e+00 - val_loss: 0.4884 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.0000e+00 - val_loss: 0.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.0000e+00 - val_loss: 0.4862 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.0000e+00 - val_loss: 0.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.0000e+00 - val_loss: 0.4771 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.0000e+00 - val_loss: 0.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.0000e+00 - val_loss: 0.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.0000e+00 - val_loss: 0.5072 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.0000e+00 - val_loss: 0.4834 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.0000e+00 - val_loss: 0.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.0000e+00 - val_loss: 0.4781 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.0000e+00 - val_loss: 0.4808 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/350\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.0000e+00 - val_loss: 0.4741 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.0000e+00 - val_loss: 0.4914 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.0000e+00 - val_loss: 0.5022 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.0000e+00 - val_loss: 0.5073 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.0000e+00 - val_loss: 0.4995 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.0000e+00 - val_loss: 0.4822 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.0000e+00 - val_loss: 0.4814 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.0000e+00 - val_loss: 0.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.0000e+00 - val_loss: 0.4809 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.0000e+00 - val_loss: 0.4677 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.0000e+00 - val_loss: 0.4965 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.0000e+00 - val_loss: 0.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.0000e+00 - val_loss: 0.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.0000e+00 - val_loss: 0.4833 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.0000e+00 - val_loss: 0.4948 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.0000e+00 - val_loss: 0.5009 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.0000e+00 - val_loss: 0.5253 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.0000e+00 - val_loss: 0.5007 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.0000e+00 - val_loss: 0.4893 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.0000e+00 - val_loss: 0.4872 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.0000e+00 - val_loss: 0.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.0000e+00 - val_loss: 0.4794 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.0000e+00 - val_loss: 0.4830 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.0000e+00 - val_loss: 0.4798 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/350\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.0000e+00 - val_loss: 0.4910 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.0000e+00 - val_loss: 0.4867 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.0000e+00 - val_loss: 0.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.0000e+00 - val_loss: 0.5011 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.0000e+00 - val_loss: 0.4965 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.0000e+00 - val_loss: 0.4829 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.0000e+00 - val_loss: 0.4721 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.0000e+00 - val_loss: 0.4819 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/350\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.0000e+00 - val_loss: 0.4836 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/350\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.0000e+00 - val_loss: 0.4728 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/350\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.0000e+00 - val_loss: 0.4812 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/350\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.0000e+00 - val_loss: 0.4909 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "EPOCH = 350\n",
    "Network_Regressor=NN_model_Regressor.fit(X_Train_S, Y_Train, validation_data=(X_Test_S,Y_Test), epochs=EPOCH, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "found-rogers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = Network_Regressor.history['loss']\n",
    "loss_val = Network_Regressor.history['val_loss']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, loss_train, 'r', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-distinction",
   "metadata": {},
   "source": [
    " Pickling the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sound-canada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "R_json = NN_model_Regressor.to_json()\n",
    "with open(\"Regressor_model.json\", \"w\") as json_file:\n",
    "    json_file.write(R_json)\n",
    "\n",
    "NN_model_Regressor.save_weights(\"Regressor_model.h5\")\n",
    "print(\"Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
